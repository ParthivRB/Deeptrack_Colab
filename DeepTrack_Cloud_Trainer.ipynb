{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthivRB/Deeptrack_Colab/blob/main/DeepTrack_Cloud_Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# üéØ DeepTrack2 Cloud Training System - OPTIMIZED VERSION\n",
        "# ============================================================================\n",
        "# Version: 2.0.0 | Incremental Training + Performance Optimizations\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üöÄ DEEPTRACK CLOUD TRAINER\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nInitializing training environment.. .\\n\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 1: Install Dependencies\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = [\n",
        "    'deeptrack', 'deeplay', 'torch', 'torchvision',\n",
        "    'tqdm', 'ipywidgets', 'matplotlib', 'scikit-image',\n",
        "    'pandas', 'scipy'\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "\n",
        "print(\"‚úÖ All dependencies installed!\\n\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 2: Import Libraries\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"üìö Loading libraries...\")\n",
        "\n",
        "import os\n",
        "import json\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "import hashlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy. ndimage import label, center_of_mass\n",
        "from skimage import io as skio\n",
        "from tqdm. auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import deeplay as dl\n",
        "import deeptrack as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"‚úÖ Libraries loaded!\")\n",
        "print(f\"üñ•Ô∏è  Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"   PyTorch:  {torch.__version__}\")\n",
        "print(f\"   DeepTrack: installed\\n\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 3: Mount Google Drive\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"üìÇ Mounting Google Drive...\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "BASE_PATH = Path('/content/drive/MyDrive/DeepTrack_Studio')\n",
        "DATA_PATH = BASE_PATH / 'training_data'\n",
        "MODEL_PATH = BASE_PATH / 'models'\n",
        "LOG_PATH = BASE_PATH / 'logs'\n",
        "CACHE_PATH = BASE_PATH / 'cache'\n",
        "\n",
        "for path in [BASE_PATH, DATA_PATH, MODEL_PATH, LOG_PATH, CACHE_PATH]:\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "(DATA_PATH / 'videos').mkdir(exist_ok=True)\n",
        "(DATA_PATH / 'annotations').mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Google Drive ready!\")\n",
        "print(f\"   Base:  {BASE_PATH}\\n\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 4: Training Tracker (NEW - for incremental training)\n",
        "# -----------------------------------------------------------------------------\n",
        "class TrainingTracker:\n",
        "    def __init__(self, cache_path):\n",
        "        self.cache_path = Path(cache_path)\n",
        "        self.tracker_file = self.cache_path / 'training_tracker.json'\n",
        "        self.trained_videos = self.load_tracker()\n",
        "\n",
        "    def load_tracker(self):\n",
        "        if self.tracker_file.exists():\n",
        "            with open(self.tracker_file, 'r') as f:\n",
        "                return json.load(f)\n",
        "        return {}\n",
        "\n",
        "    def save_tracker(self):\n",
        "        with open(self.tracker_file, 'w') as f:\n",
        "            json. dump(self.trained_videos, f, indent=2)\n",
        "\n",
        "    def get_file_hash(self, file_path):\n",
        "        \"\"\"Generate hash of file to detect changes\"\"\"\n",
        "        with open(file_path, 'rb') as f:\n",
        "            return hashlib.md5(f.read()).hexdigest()\n",
        "\n",
        "    def is_video_trained(self, video_path):\n",
        "        video_name = video_path.name\n",
        "        if video_name not in self.trained_videos:\n",
        "            return False\n",
        "\n",
        "        current_hash = self.get_file_hash(video_path)\n",
        "        return self.trained_videos[video_name]. get('hash') == current_hash\n",
        "\n",
        "    def mark_video_trained(self, video_path, model_version):\n",
        "        video_name = video_path.name\n",
        "        self.trained_videos[video_name] = {\n",
        "            'hash':  self.get_file_hash(video_path),\n",
        "            'trained_date': datetime.now().isoformat(),\n",
        "            'model_version': model_version\n",
        "        }\n",
        "        self.save_tracker()\n",
        "\n",
        "    def get_untrained_videos(self, video_files):\n",
        "        return [v for v in video_files if not self.is_video_trained(v)]\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 5: Data Loader (OPTIMIZED with caching)\n",
        "# -----------------------------------------------------------------------------\n",
        "class TrainingDataLoader:\n",
        "    def __init__(self, data_path, cache_path):\n",
        "        self.data_path = Path(data_path)\n",
        "        self.cache_path = Path(cache_path)\n",
        "        self.videos_path = self.data_path / 'videos'\n",
        "        self.annotations_path = self.data_path / 'annotations'\n",
        "        self.video_files = []\n",
        "        self.annotation_files = {}\n",
        "\n",
        "    def scan_data(self):\n",
        "        print(\"üîç Scanning for training data...\")\n",
        "        video_extensions = ['.tif', '.tiff', '.png', '.jpg']\n",
        "        self.video_files = []\n",
        "        for ext in video_extensions:\n",
        "            self.video_files.extend(list(self.videos_path. glob(f\"*{ext}\")))\n",
        "\n",
        "        if not self.video_files:\n",
        "            print(f\"‚ùå No videos found!\")\n",
        "            print(f\"\\nüìù UPLOAD INSTRUCTIONS:\")\n",
        "            print(f\"   1. Open Google Drive in new tab\")\n",
        "            print(f\"   2. Go to:  {self.videos_path}\")\n",
        "            print(f\"   3. Upload your . tif video files\")\n",
        "            print(f\"   4. Return here and re-run this cell\")\n",
        "            return False\n",
        "\n",
        "        print(f\"‚úÖ Found {len(self.video_files)} video(s)\")\n",
        "\n",
        "        self.annotation_files = {}\n",
        "        for video_path in self.video_files:\n",
        "            annotation_path = self.annotations_path / f\"{video_path.stem}_particles.csv\"\n",
        "            if annotation_path. exists():\n",
        "                self.annotation_files[video_path.stem] = annotation_path\n",
        "\n",
        "        print(f\"üìã Found {len(self.annotation_files)} annotation(s)\")\n",
        "        for i, video_path in enumerate(self.video_files, 1):\n",
        "            status = \"‚úÖ\" if video_path. stem in self.annotation_files else \"‚ö†Ô∏è (no annotation)\"\n",
        "            print(f\"   {i}. {video_path.name} {status}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def load_video_cached(self, video_path):\n",
        "        \"\"\"Load video with caching for faster repeated access\"\"\"\n",
        "        cache_file = self.cache_path / f\"{video_path.stem}_processed.npy\"\n",
        "\n",
        "        if cache_file.exists():\n",
        "            return np.load(cache_file)\n",
        "\n",
        "        video = skio.imread(str(video_path))\n",
        "        if video.ndim == 2:\n",
        "            video = video[np.newaxis, ...]\n",
        "        elif video.ndim == 4:\n",
        "            video = video[:, 0, :, :]\n",
        "        if video.max() > 0:\n",
        "            video = video. astype(np.float32) / video.max()\n",
        "\n",
        "        # Save to cache\n",
        "        np.save(cache_file, video)\n",
        "        return video\n",
        "\n",
        "    def load_annotations(self, video_stem):\n",
        "        if video_stem not in self.annotation_files:\n",
        "            return None\n",
        "        df = pd.read_csv(self.annotation_files[video_stem])\n",
        "        return df\n",
        "\n",
        "    def create_ground_truth_masks(self, annotations, shape, radius=3):\n",
        "        num_frames, height, width = shape\n",
        "        masks = np.zeros(shape, dtype=np.float32)\n",
        "        yy, xx = np.ogrid[: height, :width]\n",
        "        for frame_idx in range(num_frames):\n",
        "            frame_particles = annotations[annotations['frame'] == frame_idx]\n",
        "            for _, particle in frame_particles.iterrows():\n",
        "                x, y = int(particle['x']), int(particle['y'])\n",
        "                distance = (xx - x)**2 + (yy - y)**2\n",
        "                masks[frame_idx][distance <= radius**2] = 1.0\n",
        "        return masks\n",
        "\n",
        "    def preview_data(self, video_idx=0, frame_idx=0):\n",
        "        if not self.video_files:\n",
        "            return\n",
        "        video_path = self.video_files[video_idx]\n",
        "        video = self.load_video_cached(video_path)\n",
        "        annotations = self.load_annotations(video_path.stem)\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        axes[0].imshow(video[frame_idx], cmap='gray')\n",
        "        axes[0].set_title(f\"{video_path.name} - Frame {frame_idx}\")\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        axes[1].imshow(video[frame_idx], cmap='gray')\n",
        "        if annotations is not None:\n",
        "            frame_particles = annotations[annotations['frame'] == frame_idx]\n",
        "            if not frame_particles.empty:\n",
        "                axes[1].scatter(frame_particles['x'], frame_particles['y'],\n",
        "                              c='red', s=50, marker='o', facecolors='none', linewidths=2)\n",
        "            axes[1].set_title(f\"Annotations ({len(frame_particles)} particles)\")\n",
        "        else:\n",
        "            axes[1].set_title(\"No annotations\")\n",
        "        axes[1].axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Initialize tracker and data loader\n",
        "tracker = TrainingTracker(CACHE_PATH)\n",
        "data_loader = TrainingDataLoader(DATA_PATH, CACHE_PATH)\n",
        "data_available = data_loader.scan_data()\n",
        "\n",
        "if data_available:\n",
        "    print(\"\\nüì∏ Preview:\")\n",
        "    data_loader.preview_data(video_idx=0, frame_idx=0)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 6: Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "class TrainingConfig:\n",
        "    def __init__(self):\n",
        "        self.widgets = {}\n",
        "        self.widgets['model_name'] = widgets.Text(value='particle_detector', description='Model Name: ')\n",
        "        self.widgets['architecture'] = widgets. Dropdown(options=['UNet'], value='UNet', description='Architecture:')\n",
        "        self.widgets['unet_channels'] = widgets.Text(value='16,32,64', description='Channels:')\n",
        "        self.widgets['epochs'] = widgets.IntSlider(value=30, min=10, max=100, description='Epochs:')\n",
        "        self.widgets['batch_size'] = widgets. Dropdown(options=[2,4,8,16], value=8, description='Batch Size:')\n",
        "        self.widgets['learning_rate'] = widgets.FloatLogSlider(value=1e-4, base=10, min=-6, max=-2, description='Learning Rate:')\n",
        "        self.widgets['validation_split'] = widgets.FloatSlider(value=0.2, min=0.1, max=0.4, description='Val Split:')\n",
        "        self.widgets['augmentation'] = widgets.Checkbox(value=True, description='Augmentation')\n",
        "        self.widgets['particle_radius'] = widgets.IntSlider(value=3, min=1, max=10, description='Particle Radius:')\n",
        "        self.widgets['incremental_training'] = widgets. Checkbox(value=True, description='Incremental Training')\n",
        "\n",
        "    def display(self):\n",
        "        display(HTML(\"<h3>‚öôÔ∏è Training Configuration</h3>\"))\n",
        "        display(widgets.VBox([\n",
        "            self.widgets['model_name'],\n",
        "            self.widgets['architecture'],\n",
        "            self.widgets['unet_channels'],\n",
        "            self. widgets['epochs'],\n",
        "            self. widgets['batch_size'],\n",
        "            self.widgets['learning_rate'],\n",
        "            self.widgets['validation_split'],\n",
        "            self.widgets['augmentation'],\n",
        "            self.widgets['particle_radius'],\n",
        "            self.widgets['incremental_training']\n",
        "        ]))\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            'model':  {\n",
        "                'name': self.widgets['model_name'].value,\n",
        "                'architecture': self.widgets['architecture'].value. lower(),\n",
        "                'unet_channels': [int(x. strip()) for x in self.widgets['unet_channels'].value. split(',')]\n",
        "            },\n",
        "            'training':  {\n",
        "                'epochs': self. widgets['epochs'].value,\n",
        "                'batch_size': self.widgets['batch_size'].value,\n",
        "                'learning_rate':  self.widgets['learning_rate']. value,\n",
        "                'validation_split': self.widgets['validation_split'].value,\n",
        "                'incremental':  self.widgets['incremental_training'].value\n",
        "            },\n",
        "            'augmentation': {\n",
        "                'enabled': self.widgets['augmentation'].value,\n",
        "                'flip_lr': True,\n",
        "                'flip_ud': True,\n",
        "                'rotate': True,\n",
        "                'brightness': True\n",
        "            },\n",
        "            'data': {\n",
        "                'particle_radius': self.widgets['particle_radius'].value\n",
        "            }\n",
        "        }\n",
        "\n",
        "config_manager = TrainingConfig()\n",
        "config_manager.display()\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 7: Dataset (OPTIMIZED - fixed stride issue)\n",
        "# -----------------------------------------------------------------------------\n",
        "class ParticleDataset(Dataset):\n",
        "    def __init__(self, frames, masks, augmentation_config=None):\n",
        "        self.frames = frames\n",
        "        self.masks = masks\n",
        "        self.aug_config = augmentation_config or {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame = self.frames[idx]. copy()\n",
        "        mask = self. masks[idx].copy()\n",
        "\n",
        "        if self.aug_config. get('enabled', False):\n",
        "            if self.aug_config. get('flip_lr') and np.random.rand() > 0.5:\n",
        "                frame = np.fliplr(frame)\n",
        "                mask = np.fliplr(mask)\n",
        "            if self.aug_config.get('flip_ud') and np.random.rand() > 0.5:\n",
        "                frame = np.flipud(frame)\n",
        "                mask = np.flipud(mask)\n",
        "            if self.aug_config.get('rotate') and np.random.rand() > 0.5:\n",
        "                k = np.random.randint(1, 4)\n",
        "                frame = np.rot90(frame, k)\n",
        "                mask = np.rot90(mask, k)\n",
        "            if self.aug_config.get('brightness') and np.random.rand() > 0.5:\n",
        "                frame = np.clip(frame * np.random.uniform(0.8, 1.2), 0, 1)\n",
        "\n",
        "        # FIX: Ensure contiguous arrays before converting to tensors\n",
        "        frame = np.ascontiguousarray(frame)\n",
        "        mask = np.ascontiguousarray(mask)\n",
        "\n",
        "        frame = torch.from_numpy(frame).float().unsqueeze(0)\n",
        "        mask = torch.from_numpy(mask).float().unsqueeze(0)\n",
        "        return frame, mask\n",
        "\n",
        "def prepare_datasets(data_loader, config, video_files_to_train=None):\n",
        "    \"\"\"Prepare datasets - optionally only for specific videos (incremental training)\"\"\"\n",
        "    print(\"\\nüì¶ Preparing datasets...\")\n",
        "    all_frames, all_masks = [], []\n",
        "\n",
        "    videos_to_process = video_files_to_train if video_files_to_train else data_loader.video_files\n",
        "\n",
        "    for video_path in tqdm(videos_to_process, desc=\"Loading\"):\n",
        "        video = data_loader.load_video_cached(video_path)\n",
        "        annotations = data_loader.load_annotations(video_path.stem)\n",
        "\n",
        "        if annotations is not None:\n",
        "            masks = data_loader.create_ground_truth_masks(annotations, video.shape, config['data']['particle_radius'])\n",
        "        else:\n",
        "            masks = np. zeros_like(video)\n",
        "\n",
        "        all_frames. append(video)\n",
        "        all_masks.append(masks)\n",
        "\n",
        "    all_frames = np.concatenate(all_frames, axis=0)\n",
        "    all_masks = np. concatenate(all_masks, axis=0)\n",
        "\n",
        "    val_split = config['training']['validation_split']\n",
        "    n_val = int(len(all_frames) * val_split)\n",
        "    indices = np.random.permutation(len(all_frames))\n",
        "\n",
        "    train_dataset = ParticleDataset(all_frames[indices[n_val:]], all_masks[indices[n_val:]], config['augmentation'])\n",
        "    val_dataset = ParticleDataset(all_frames[indices[:n_val]], all_masks[indices[:n_val]])\n",
        "\n",
        "    # OPTIMIZATION: Use pin_memory for faster GPU transfer, increase num_workers\n",
        "    num_workers = 2 if device.type == 'cuda' else 0\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config['training']['batch_size'],\n",
        "                             shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config['training']['batch_size'],\n",
        "                           shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    print(f\"‚úÖ Train:  {len(train_dataset)}, Val: {len(val_dataset)}\")\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 8: Model (OPTIMIZED PyTorch UNet)\n",
        "# -----------------------------------------------------------------------------\n",
        "def create_model(config):\n",
        "    print(f\"\\nüèóÔ∏è Building {config['model']['architecture']. upper()} model...\")\n",
        "\n",
        "    class UNet(nn.Module):\n",
        "        def __init__(self, in_channels=1, out_channels=1, features=[16, 32, 64]):\n",
        "            super(UNet, self).__init__()\n",
        "            self.encoder = nn.ModuleList()\n",
        "            self.decoder = nn.ModuleList()\n",
        "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "            # Encoder\n",
        "            for feature in features:\n",
        "                self.encoder.append(\n",
        "                    nn.Sequential(\n",
        "                        nn.Conv2d(in_channels, feature, kernel_size=3, padding=1),\n",
        "                        nn.BatchNorm2d(feature),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Conv2d(feature, feature, kernel_size=3, padding=1),\n",
        "                        nn.BatchNorm2d(feature),\n",
        "                        nn.ReLU(inplace=True)\n",
        "                    )\n",
        "                )\n",
        "                in_channels = feature\n",
        "\n",
        "            # Decoder\n",
        "            for feature in reversed(features):\n",
        "                self.decoder.append(\n",
        "                    nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n",
        "                )\n",
        "                self.decoder.append(\n",
        "                    nn.Sequential(\n",
        "                        nn.Conv2d(feature * 2, feature, kernel_size=3, padding=1),\n",
        "                        nn.BatchNorm2d(feature),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Conv2d(feature, feature, kernel_size=3, padding=1),\n",
        "                        nn.BatchNorm2d(feature),\n",
        "                        nn.ReLU(inplace=True)\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            self.bottleneck = nn.Sequential(\n",
        "                nn.Conv2d(features[-1], features[-1] * 2, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(features[-1] * 2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(features[-1] * 2, features[-1] * 2, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(features[-1] * 2),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "            self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "        def forward(self, x):\n",
        "            skip_connections = []\n",
        "\n",
        "            for encode in self.encoder:\n",
        "                x = encode(x)\n",
        "                skip_connections.append(x)\n",
        "                x = self.pool(x)\n",
        "\n",
        "            x = self.bottleneck(x)\n",
        "            skip_connections = skip_connections[::-1]\n",
        "\n",
        "            for idx in range(0, len(self.decoder), 2):\n",
        "                x = self.decoder[idx](x)\n",
        "                skip_connection = skip_connections[idx // 2]\n",
        "\n",
        "                if x.shape != skip_connection.shape:\n",
        "                    x = nn. functional.interpolate(x, size=skip_connection.shape[2:])\n",
        "\n",
        "                concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "                x = self.decoder[idx + 1](concat_skip)\n",
        "\n",
        "            return self.final_conv(x)\n",
        "\n",
        "    model = UNet(\n",
        "        in_channels=1,\n",
        "        out_channels=1,\n",
        "        features=config['model']['unet_channels']\n",
        "    )\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"‚úÖ Model created!  Parameters: {total_params:,}\")\n",
        "\n",
        "    if total_params == 0:\n",
        "        raise ValueError(\"Model has 0 parameters!  Check UNet initialization.\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 9: Trainer (OPTIMIZED + Incremental Training Support)\n",
        "# -----------------------------------------------------------------------------\n",
        "class Trainer:\n",
        "    def __init__(self, model, config, save_dir):\n",
        "        self.model = model. to(device)\n",
        "        self.config = config\n",
        "        self.save_dir = Path(save_dir)\n",
        "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
        "        self.scheduler = torch.optim. lr_scheduler. ReduceLROnPlateau(self.optimizer, mode='min', patience=5, verbose=True)\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.history = {'train_loss': [], 'val_loss': [], 'train_iou': [], 'val_iou': []}\n",
        "        self. best_val_loss = float('inf')\n",
        "        self.start_epoch = 0\n",
        "\n",
        "    def _calculate_iou(self, pred, target, threshold=0.5):\n",
        "        pred_binary = (pred > threshold).float()\n",
        "        target_binary = (target > threshold).float()\n",
        "        intersection = (pred_binary * target_binary).sum()\n",
        "        union = pred_binary.sum() + target_binary.sum() - intersection\n",
        "        return (intersection / union).item() if union > 0 else 1.0\n",
        "\n",
        "    def train_epoch(self, train_loader):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        total_iou = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=\"Training\")\n",
        "        for frames, masks in pbar:\n",
        "            frames, masks = frames.to(device), masks.to(device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self. model(frames)\n",
        "            loss = self.criterion(outputs, masks)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                iou = self._calculate_iou(torch.sigmoid(outputs), masks)\n",
        "\n",
        "            total_loss += loss. item()\n",
        "            total_iou += iou\n",
        "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'iou': f\"{iou:.4f}\"})\n",
        "\n",
        "        return total_loss / len(train_loader), total_iou / len(train_loader)\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        total_iou = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for frames, masks in tqdm(val_loader, desc=\"Validation\"):\n",
        "                frames, masks = frames.to(device), masks.to(device)\n",
        "                outputs = self.model(frames)\n",
        "                loss = self.criterion(outputs, masks)\n",
        "                iou = self._calculate_iou(torch.sigmoid(outputs), masks)\n",
        "                total_loss += loss.item()\n",
        "                total_iou += iou\n",
        "\n",
        "        return total_loss / len(val_loader), total_iou / len(val_loader)\n",
        "\n",
        "    def load_checkpoint(self, checkpoint_path):\n",
        "        \"\"\"Load existing model for incremental training\"\"\"\n",
        "        if Path(checkpoint_path).exists():\n",
        "            print(f\"üì• Loading existing model from {checkpoint_path}\")\n",
        "            checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            self.history = checkpoint. get('history', self.history)\n",
        "            self.start_epoch = checkpoint.get('epoch', 0)\n",
        "            self.best_val_loss = min(self.history. get('val_loss', [float('inf')]))\n",
        "            print(f\"‚úÖ Loaded model from epoch {self.start_epoch}\")\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def save_checkpoint(self, epoch, is_best=False):\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'history':  self.history,\n",
        "            'config': self.config\n",
        "        }\n",
        "\n",
        "        # Always save latest\n",
        "        torch.save(checkpoint, self.save_dir / \"latest_model.pth\")\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            torch.save(checkpoint, self.save_dir / f\"checkpoint_epoch{epoch}.pth\")\n",
        "\n",
        "        if is_best:\n",
        "            torch.save(checkpoint, self.save_dir / \"best_model.pth\")\n",
        "            print(f\"   üíæ Best model saved (loss: {self.best_val_loss:.4f})\")\n",
        "\n",
        "    def plot_progress(self):\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "        axes[0].plot(self.history['train_loss'], label='Train', marker='o')\n",
        "        axes[0].plot(self.history['val_loss'], label='Val', marker='s')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Loss')\n",
        "        axes[0].set_title('Loss')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True)\n",
        "\n",
        "        axes[1].plot(self.history['train_iou'], label='Train', marker='o')\n",
        "        axes[1].plot(self.history['val_iou'], label='Val', marker='s')\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('IoU')\n",
        "        axes[1].set_title('IoU')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True)\n",
        "\n",
        "        plt. tight_layout()\n",
        "        plt.savefig(self.save_dir / 'training_progress. png', dpi=150)\n",
        "        plt.show()\n",
        "\n",
        "    def train(self, train_loader, val_loader, epochs):\n",
        "        print(f\"\\nüöÄ Starting training for {epochs} epochs.. .\\n\")\n",
        "\n",
        "        for epoch in range(self.start_epoch + 1, self.start_epoch + epochs + 1):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Epoch {epoch}/{self.start_epoch + epochs}\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            train_loss, train_iou = self.train_epoch(train_loader)\n",
        "            val_loss, val_iou = self.validate(val_loader)\n",
        "\n",
        "            self.history['train_loss']. append(train_loss)\n",
        "            self.history['val_loss']. append(val_loss)\n",
        "            self.history['train_iou'].append(train_iou)\n",
        "            self.history['val_iou'].append(val_iou)\n",
        "\n",
        "            # FIX: Removed space before . 4f\n",
        "            print(f\"\\nüìä Summary:\")\n",
        "            print(f\"   Train - Loss: {train_loss:.4f}, IoU: {train_iou:. 4f}\")\n",
        "            print(f\"   Val   - Loss: {val_loss:. 4f}, IoU: {val_iou:.4f}\")\n",
        "\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            is_best = val_loss < self.best_val_loss\n",
        "            if is_best:\n",
        "                self. best_val_loss = val_loss\n",
        "\n",
        "            self.save_checkpoint(epoch, is_best)\n",
        "\n",
        "            if epoch % 5 == 0:\n",
        "                clear_output(wait=True)\n",
        "                self.plot_progress()\n",
        "\n",
        "        print(f\"\\n‚úÖ Training complete! Best val loss: {self.best_val_loss:.4f}\")\n",
        "        self.plot_progress()\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 10: Model Exporter\n",
        "# -----------------------------------------------------------------------------\n",
        "class ModelExporter:\n",
        "    def __init__(self, model_path):\n",
        "        self.model_path = Path(model_path)\n",
        "\n",
        "    def generate_version(self):\n",
        "        return f\"v_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "    def export_model(self, trainer, config):\n",
        "        version = self.generate_version()\n",
        "        export_dir = self.model_path / version\n",
        "        export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        print(f\"\\nüì¶ Exporting model:  {version}\")\n",
        "\n",
        "        torch.save(trainer.model. state_dict(), export_dir / \"weights.pth\")\n",
        "\n",
        "        metadata = {\n",
        "            \"model_name\": config['model']['name'],\n",
        "            \"version\": version,\n",
        "            \"created_at\": datetime.now().isoformat(),\n",
        "            \"architecture\": {\n",
        "                \"type\": config['model']['architecture'],\n",
        "                \"input_shape\": [1, 512, 512],\n",
        "                \"unet_channels\": config['model']['unet_channels'],\n",
        "                \"out_channels\": 1\n",
        "            },\n",
        "            \"training\":  config['training'],\n",
        "            \"performance\": {\n",
        "                \"final_train_loss\": trainer.history['train_loss'][-1],\n",
        "                \"final_val_loss\": trainer.history['val_loss'][-1],\n",
        "                \"best_val_loss\": trainer.best_val_loss,\n",
        "                \"final_train_iou\": trainer. history['train_iou'][-1],\n",
        "                \"final_val_iou\": trainer.history['val_iou'][-1],\n",
        "                \"best_val_iou\": max(trainer.history['val_iou'])\n",
        "            },\n",
        "            \"data_info\": {\n",
        "                \"num_videos\": len(data_loader.video_files),\n",
        "                \"augmentation\":  config['augmentation']['enabled']\n",
        "            },\n",
        "            \"compatibility\": {\n",
        "                \"deeptrack_version\": \"installed\",\n",
        "                \"torch_version\":  torch.__version__,\n",
        "                \"python_version\": f\"{sys.version_info.major}.{sys.version_info. minor}\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open(export_dir / \"metadata.json\", 'w') as f:\n",
        "            json.dump(metadata, f, indent=2)\n",
        "\n",
        "        with open(export_dir / \"config.json\", 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        shutil.copy(trainer.save_dir / 'training_progress.png', export_dir / 'training_progress.png')\n",
        "\n",
        "        card = f\"\"\"# Model:  {config['model']['name']}\n",
        "\n",
        "**Version:** {version}\n",
        "**Created:** {metadata['created_at']}\n",
        "**Architecture:** {metadata['architecture']['type']. upper()}\n",
        "\n",
        "## Performance\n",
        "\n",
        "| Metric | Train | Validation | Best |\n",
        "|--------|-------|------------|------|\n",
        "| Loss | {metadata['performance']['final_train_loss']:.4f} | {metadata['performance']['final_val_loss']:.4f} | {metadata['performance']['best_val_loss']:.4f} |\n",
        "| IoU | {metadata['performance']['final_train_iou']:. 4f} | {metadata['performance']['final_val_iou']:.4f} | {metadata['performance']['best_val_iou']:.4f} |\n",
        "\n",
        "## Architecture\n",
        "\n",
        "- Type: {metadata['architecture']['type']. upper()}\n",
        "- Channels: {metadata['architecture']['unet_channels']}\n",
        "- Input:  {metadata['architecture']['input_shape']}\n",
        "\n",
        "## Training\n",
        "\n",
        "- Epochs: {config['training']['epochs']}\n",
        "- Batch Size: {config['training']['batch_size']}\n",
        "- Learning Rate: {config['training']['learning_rate']}\n",
        "\n",
        "## Usage\n",
        "\n",
        "Download this model to your local DeepTrack MPT Studio app!\n",
        "\n",
        "```python\n",
        "from src.engines.ai_engine import DeepTrackEngine\n",
        "engine = DeepTrackEngine()\n",
        "engine.load_model(\"weights.pth\", \"metadata.json\")\n",
        "\"\"\"\n",
        "\n",
        "    with open(export_dir / \"model_card.md\", 'w') as f:\n",
        "        f. write(card)\n",
        "\n",
        "    print(f\"‚úÖ Model exported to: {export_dir}\")\n",
        "    print(f\"\\nüì• DOWNLOAD INSTRUCTIONS:\")\n",
        "    print(f\"   1. Open Google Drive\")\n",
        "    print(f\"   2. Navigate to: {export_dir}\")\n",
        "    print(f\"   3. Download the entire '{version}' folder\")\n",
        "    print(f\"   4. Place it in your local app's 'models' directory\")\n",
        "\n",
        "    return export_dir"
      ],
      "metadata": {
        "id": "enhanced_setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# üéØ EXECUTE SMART TRAINING PIPELINE\n",
        "# ============================================================================\n",
        "# Incremental training:  Only trains on new/untrained videos!\n",
        "# ============================================================================\n",
        "\n",
        "config = config_manager.get_config()\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üöÄ STARTING SMART TRAINING PIPELINE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
        "print(f\"   Model: {config['model']['name']}\")\n",
        "print(f\"   Architecture: {config['model']['architecture']. upper()}\")\n",
        "print(f\"   Epochs: {config['training']['epochs']}\")\n",
        "print(f\"   Batch Size: {config['training']['batch_size']}\")\n",
        "print(f\"   Learning Rate: {config['training']['learning_rate']}\")\n",
        "print(f\"   Incremental Training: {config['training']['incremental']}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Determine which videos to train\n",
        "videos_to_train = None\n",
        "should_load_existing = False\n",
        "\n",
        "if config['training']['incremental']:\n",
        "    untrained_videos = tracker.get_untrained_videos(data_loader.video_files)\n",
        "\n",
        "    if not untrained_videos:\n",
        "        print(\"\\n‚úÖ All videos already trained!\")\n",
        "        print(\"üí° Set 'Incremental Training' to False to retrain all videos.\")\n",
        "        videos_to_train = []\n",
        "    else:\n",
        "        print(f\"\\nüÜï Found {len(untrained_videos)} new/untrained video(s):\")\n",
        "        for v in untrained_videos:\n",
        "            print(f\"   - {v.name}\")\n",
        "\n",
        "        videos_to_train = untrained_videos\n",
        "\n",
        "        # Check if we have an existing model to continue from\n",
        "        latest_model = LOG_PATH / 'current_training' / 'latest_model.pth'\n",
        "        if latest_model.exists():\n",
        "            should_load_existing = True\n",
        "            print(f\"\\nüì• Existing model found - will continue training from checkpoint\")\n",
        "        else:\n",
        "            print(f\"\\n‚ÑπÔ∏è  No existing model found - starting fresh training\")\n",
        "else:\n",
        "    print(\"\\nüîÑ Full training mode - training on all videos\")\n",
        "    videos_to_train = data_loader.video_files\n",
        "    should_load_existing = False\n",
        "\n",
        "# Exit if nothing to train\n",
        "if not videos_to_train:\n",
        "    print(\"\\n‚úã Nothing to train.  Exiting.\")\n",
        "else:\n",
        "    # Prepare datasets\n",
        "    train_loader, val_loader = prepare_datasets(data_loader, config, videos_to_train)\n",
        "\n",
        "    # Create model\n",
        "    model = create_model(config)\n",
        "    trainer = Trainer(model, config, LOG_PATH / 'current_training')\n",
        "\n",
        "    # Load existing model if incremental training is enabled AND model exists\n",
        "    if should_load_existing:\n",
        "        latest_model = LOG_PATH / 'current_training' / 'latest_model.pth'\n",
        "        try:\n",
        "            trainer.load_checkpoint(latest_model)\n",
        "            print(f\"‚úÖ Successfully loaded existing model for incremental training\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Could not load existing model: {e}\")\n",
        "            print(f\"   Starting fresh training instead...\")\n",
        "\n",
        "    # Start training\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üéØ Training on {len(videos_to_train)} video(s)\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    trainer.train(train_loader, val_loader, config['training']['epochs'])\n",
        "\n",
        "    # Mark videos as trained\n",
        "    if config['training']['incremental']:\n",
        "        version = ModelExporter(MODEL_PATH).generate_version()\n",
        "        for video_path in videos_to_train:\n",
        "            tracker.mark_video_trained(video_path, version)\n",
        "        print(f\"\\n‚úÖ Marked {len(videos_to_train)} video(s) as trained\")\n",
        "\n",
        "    # Export model\n",
        "    exporter = ModelExporter(MODEL_PATH)\n",
        "    export_dir = exporter.export_model(trainer, config)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üéâ TRAINING COMPLETE!\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\nüì¶ Model saved to: {export_dir}\")\n",
        "    print(f\"\\nüì• Download your trained model from Google Drive!\")\n",
        "    print(f\"\\nüí° Next time you upload new videos, only those will be trained!\")\n",
        "    print(\"=\" * 70)"
      ],
      "metadata": {
        "id": "enhanced_training"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}