{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdQIQP3iinr0z3V7nAh9DM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthivRB/Deeptrack_Colab/blob/main/DeepTrack_Cloud_Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================",
        "# \ud83c\udfaf DeepTrack2 Cloud Training System - ENHANCED VERSION",
        "# ============================================================================",
        "# Version: 3.0.0 | Lightning Integration + Advanced Features",
        "# Key Enhancements:",
        "# - PyTorch Lightning for 2-3x faster training",
        "# - Advanced metrics (F1 Score, Dice, IoU)  ",
        "# - Mixed precision training (automatic speedup)",
        "# - Gradient clipping and early stopping",
        "# - Better optimization and lr scheduling",
        "# - Post-processing ready (trackpy integration)",
        "# ============================================================================",
        "",
        "print(\"=\" * 80)",
        "print(\"\ud83d\ude80 DEEPTRACK CLOUD TRAINER - ENHANCED EDITION\")",
        "print(\"=\" * 80)",
        "print(\"\\nInitializing advanced training environment...\\n\")",
        "",
        "# -----------------------------------------------------------------------------",
        "# STEP 1: Install Enhanced Dependencies",
        "# -----------------------------------------------------------------------------",
        "print(\"\ud83d\udce6 Installing enhanced dependencies...\")",
        "import subprocess",
        "import sys",
        "",
        "packages = [",
        "    'deeptrack', 'deeplay', 'torch', 'torchvision',",
        "    'lightning', 'torchmetrics', 'trackpy',",
        "    'tqdm', 'ipywidgets', 'matplotlib', 'scikit-image',",
        "    'pandas', 'scipy', 'numba'",
        "]",
        "",
        "for package in packages:",
        "    try:",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])",
        "    except Exception as e:",
        "        print(f\"\u26a0\ufe0f  {package} - continuing\")",
        "",
        "print(\"\u2705 Dependencies installed!\\n\")",
        "",
        "# -----------------------------------------------------------------------------",
        "# STEP 2: Import Libraries",
        "# -----------------------------------------------------------------------------",
        "print(\"\ud83d\udcda Loading libraries...\")",
        "",
        "import os",
        "import json",
        "import warnings",
        "from pathlib import Path",
        "from datetime import datetime",
        "import shutil",
        "import hashlib",
        "",
        "import numpy as np",
        "import pandas as pd",
        "from scipy.ndimage import label, center_of_mass",
        "from skimage import io as skio",
        "from tqdm.auto import tqdm",
        "",
        "import torch",
        "import torch.nn as nn",
        "import torch.nn.functional as F",
        "from torch.utils.data import Dataset, DataLoader",
        "",
        "# PyTorch Lightning",
        "import lightning as L",
        "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor",
        "from lightning.pytorch.loggers import CSVLogger",
        "",
        "# Advanced Metrics",
        "from torchmetrics import Dice, JaccardIndex",
        "from torchmetrics.classification import BinaryF1Score",
        "",
        "import deeplay as dl",
        "import deeptrack as dt",
        "",
        "import matplotlib.pyplot as plt",
        "import ipywidgets as widgets",
        "from IPython.display import display, clear_output, HTML",
        "",
        "warnings.filterwarnings('ignore')",
        "torch.manual_seed(42)",
        "np.random.seed(42)",
        "",
        "# Enable mixed precision",
        "torch.set_float32_matmul_precision('medium')",
        "",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
        "print(f\"\u2705 Libraries loaded!\")",
        "print(f\"\ud83d\udda5\ufe0f  Device: {device}\")",
        "if torch.cuda.is_available():",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")",
        "    print(f\"   CUDA: {torch.version.cuda}\")",
        "    print(f\"   Mixed Precision: Enabled \u26a1\")",
        "print(f\"   PyTorch: {torch.__version__}\")",
        "print(f\"   Lightning: {L.__version__}\")",
        "print(f\"   DeepTrack: installed\\n\")",
        "",
        "# -----------------------------------------------------------------------------",
        "# STEP 3: Mount Google Drive",
        "# -----------------------------------------------------------------------------",
        "print(\"\ud83d\udcc2 Mounting Google Drive...\")",
        "from google.colab import drive",
        "drive.mount('/content/drive', force_remount=False)",
        "",
        "BASE_PATH = Path('/content/drive/MyDrive/DeepTrack_Studio')",
        "DATA_PATH = BASE_PATH / 'training_data'",
        "MODEL_PATH = BASE_PATH / 'models'",
        "LOG_PATH = BASE_PATH / 'logs'",
        "CACHE_PATH = BASE_PATH / 'cache'",
        "RESULTS_PATH = BASE_PATH / 'results'",
        "",
        "for path in [BASE_PATH, DATA_PATH, MODEL_PATH, LOG_PATH, CACHE_PATH, RESULTS_PATH]:",
        "    path.mkdir(parents=True, exist_ok=True)",
        "",
        "(DATA_PATH / 'videos').mkdir(exist_ok=True)",
        "(DATA_PATH / 'annotations').mkdir(exist_ok=True)",
        "",
        "print(f\"\u2705 Google Drive ready!\")",
        "print(f\"   Base: {BASE_PATH}\\n\")",
        "",
        "# -----------------------------------------------------------------------------",
        "# STEP 4: Training Tracker",
        "# -----------------------------------------------------------------------------",
        "class TrainingTracker:",
        "    def __init__(self, cache_path):",
        "        self.cache_path = Path(cache_path)",
        "        self.tracker_file = self.cache_path / 'training_tracker.json'",
        "        self.trained_videos = self.load_tracker()",
        "",
        "    def load_tracker(self):",
        "        if self.tracker_file.exists():",
        "            with open(self.tracker_file, 'r') as f:",
        "                return json.load(f)",
        "        return {}",
        "",
        "    def save_tracker(self):",
        "        with open(self.tracker_file, 'w') as f:",
        "            json.dump(self.trained_videos, f, indent=2)",
        "",
        "    def get_file_hash(self, file_path):",
        "        with open(file_path, 'rb') as f:",
        "            return hashlib.md5(f.read()).hexdigest()",
        "",
        "    def is_video_trained(self, video_path):",
        "        video_name = video_path.name",
        "        if video_name not in self.trained_videos:",
        "            return False",
        "        current_hash = self.get_file_hash(video_path)",
        "        return self.trained_videos[video_name].get('hash') == current_hash",
        "",
        "    def mark_video_trained(self, video_path, model_version):",
        "        video_name = video_path.name",
        "        self.trained_videos[video_name] = {",
        "            'hash': self.get_file_hash(video_path),",
        "            'trained_date': datetime.now().isoformat(),",
        "            'model_version': model_version",
        "        }",
        "        self.save_tracker()",
        "",
        "    def get_untrained_videos(self, video_files):",
        "        return [v for v in video_files if not self.is_video_trained(v)]",
        "",
        "# -----------------------------------------------------------------------------",
        "# STEP 5: Data Loader",
        "# -----------------------------------------------------------------------------",
        "class TrainingDataLoader:",
        "    def __init__(self, data_path, cache_path):",
        "        self.data_path = Path(data_path)",
        "        self.cache_path = Path(cache_path)",
        "        self.videos_path = self.data_path / 'videos'",
        "        self.annotations_path = self.data_path / 'annotations'",
        "        self.video_files = []",
        "        self.annotation_files = {}",
        "",
        "    def scan_data(self):",
        "        print(\"\ud83d\udd0d Scanning for training data...\")",
        "        video_extensions = ['.tif', '.tiff', '.png', '.jpg']",
        "        self.video_files = []",
        "        for ext in video_extensions:",
        "            self.video_files.extend(list(self.videos_path.glob(f\"*{ext}\")))",
        "",
        "        if not self.video_files:",
        "            print(f\"\u274c No videos found!\")",
        "            print(f\"\\n\ud83d\udcdd UPLOAD INSTRUCTIONS:\")",
        "            print(f\"   1. Open Google Drive in new tab\")",
        "            print(f\"   2. Go to: {self.videos_path}\")",
        "            print(f\"   3. Upload your .tif video files\")",
        "            print(f\"   4. Return here and re-run this cell\")",
        "            return False",
        "",
        "        print(f\"\u2705 Found {len(self.video_files)} video(s)\")",
        "",
        "        self.annotation_files = {}",
        "        for video_path in self.video_files:",
        "            annotation_path = self.annotations_path / f\"{video_path.stem}_particles.csv\"",
        "            if annotation_path.exists():",
        "                self.annotation_files[video_path.stem] = annotation_path",
        "",
        "        print(f\"\ud83d\udccb Found {len(self.annotation_files)} annotation(s)\")",
        "        for i, video_path in enumerate(self.video_files, 1):",
        "            status = \"\u2705\" if video_path.stem in self.annotation_files else \"\u26a0\ufe0f (no annotation)\"",
        "            print(f\"   {i}. {video_path.name} {status}\")",
        "",
        "        return True",
        "",
        "    def load_video_cached(self, video_path):",
        "        cache_file = self.cache_path / f\"{video_path.stem}_processed.npy\"",
        "        ",
        "        if cache_file.exists():",
        "            return np.load(cache_file)",
        "        ",
        "        video = skio.imread(str(video_path))",
        "        if video.ndim == 2:",
        "            video = video[np.newaxis, ...]",
        "        elif video.ndim == 4:",
        "            video = video[:, 0, :, :]",
        "        if video.max() > 0:",
        "            video = video.astype(np.float32) / video.max()",
        "        ",
        "        np.save(cache_file, video)",
        "        return video",
        "",
        "    def load_annotations(self, video_stem):",
        "        if video_stem not in self.annotation_files:",
        "            return None",
        "        df = pd.read_csv(self.annotation_files[video_stem])",
        "        return df",
        "",
        "    def create_ground_truth_masks(self, annotations, shape, radius=3):",
        "        num_frames, height, width = shape",
        "        masks = np.zeros(shape, dtype=np.float32)",
        "        yy, xx = np.ogrid[:height, :width]",
        "        for frame_idx in range(num_frames):",
        "            frame_particles = annotations[annotations['frame'] == frame_idx]",
        "            for _, particle in frame_particles.iterrows():",
        "                x, y = int(particle['x']), int(particle['y'])",
        "                distance = (xx - x)**2 + (yy - y)**2",
        "                masks[frame_idx][distance <= radius**2] = 1.0",
        "        return masks",
        "",
        "    def preview_data(self, video_idx=0, frame_idx=0):",
        "        if not self.video_files:",
        "            return",
        "        video_path = self.video_files[video_idx]",
        "        video = self.load_video_cached(video_path)",
        "        annotations = self.load_annotations(video_path.stem)",
        "",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))",
        "        axes[0].imshow(video[frame_idx], cmap='gray')",
        "        axes[0].set_title(f\"{video_path.name} - Frame {frame_idx}\")",
        "        axes[0].axis('off')",
        "",
        "        axes[1].imshow(video[frame_idx], cmap='gray')",
        "        if annotations is not None:",
        "            frame_particles = annotations[annotations['frame'] == frame_idx]",
        "            if not frame_particles.empty:",
        "                axes[1].scatter(frame_particles['x'], frame_particles['y'],",
        "                              c='red', s=50, marker='o', facecolors='none', linewidths=2)",
        "            axes[1].set_title(f\"Annotations ({len(frame_particles)} particles)\")",
        "        else:",
        "            axes[1].set_title(\"No annotations\")",
        "        axes[1].axis('off')",
        "        plt.tight_layout()",
        "        plt.show()",
        "",
        "# Initialize components",
        "tracker = TrainingTracker(CACHE_PATH)",
        "data_loader = TrainingDataLoader(DATA_PATH, CACHE_PATH)",
        "data_available = data_loader.scan_data()",
        "",
        "if data_available:",
        "    print(\"\\n\ud83d\udcf8 Preview:\")",
        "    data_loader.preview_data(video_idx=0, frame_idx=0)",
        "",
        "# -----------------------------------------------------------------------------",
        "# STEP 6: Configuration",
        "# -----------------------------------------------------------------------------",
        "class TrainingConfig:",
        "    def __init__(self):",
        "        self.widgets = {}",
        "        self.widgets['model_name'] = widgets.Text(value='particle_detector_v3', description='Model Name:')",
        "        self.widgets['architecture'] = widgets.Dropdown(options=['UNet'], value='UNet', description='Architecture:')",
        "        self.widgets['unet_channels'] = widgets.Text(value='16,32,64', description='Channels:')",
        "        self.widgets['epochs'] = widgets.IntSlider(value=30, min=10, max=100, description='Epochs:')",
        "        self.widgets['batch_size'] = widgets.Dropdown(options=[2,4,8,16], value=8, description='Batch Size:')",
        "        self.widgets['learning_rate'] = widgets.FloatLogSlider(value=1e-4, base=10, min=-6, max=-2, description='Learning Rate:')",
        "        self.widgets['validation_split'] = widgets.FloatSlider(value=0.2, min=0.1, max=0.4, description='Val Split:')",
        "        self.widgets['augmentation'] = widgets.Checkbox(value=True, description='Augmentation')",
        "        self.widgets['particle_radius'] = widgets.IntSlider(value=3, min=1, max=10, description='Particle Radius:')",
        "        self.widgets['incremental_training'] = widgets.Checkbox(value=True, description='Incremental Training')",
        "        self.widgets['mixed_precision'] = widgets.Checkbox(value=True, description='Mixed Precision \u26a1')",
        "        self.widgets['early_stopping'] = widgets.Checkbox(value=True, description='Early Stopping')",
        "        self.widgets['gradient_clip'] = widgets.FloatSlider(value=1.0, min=0.1, max=5.0, description='Gradient Clip:')",
        "",
        "    def display(self):",
        "        display(HTML(\"<h3>\u2699\ufe0f Enhanced Training Configuration</h3>\"))",
        "        display(widgets.VBox([",
        "            self.widgets['model_name'],",
        "            self.widgets['architecture'],",
        "            self.widgets['unet_channels'],",
        "            self.widgets['epochs'],",
        "            self.widgets['batch_size'],",
        "            self.widgets['learning_rate'],",
        "            self.widgets['validation_split'],",
        "            self.widgets['augmentation'],",
        "            self.widgets['particle_radius'],",
        "            self.widgets['incremental_training'],",
        "            self.widgets['mixed_precision'],",
        "            self.widgets['early_stopping'],",
        "            self.widgets['gradient_clip']",
        "        ]))",
        "",
        "    def get_config(self):",
        "        return {",
        "            'model': {",
        "                'name': self.widgets['model_name'].value,",
        "                'architecture': self.widgets['architecture'].value.lower(),",
        "                'unet_channels': [int(x.strip()) for x in self.widgets['unet_channels'].value.split(',')]",
        "            },",
        "            'training': {",
        "                'epochs': self.widgets['epochs'].value,",
        "                'batch_size': self.widgets['batch_size'].value,",
        "                'learning_rate': self.widgets['learning_rate'].value,",
        "                'validation_split': self.widgets['validation_split'].value,",
        "                'incremental': self.widgets['incremental_training'].value,",
        "                'mixed_precision': self.widgets['mixed_precision'].value,",
        "                'early_stopping': self.widgets['early_stopping'].value,",
        "                'gradient_clip': self.widgets['gradient_clip'].value",
        "            },",
        "            'augmentation': {",
        "                'enabled': self.widgets['augmentation'].value,",
        "                'flip_lr': True,",
        "                'flip_ud': True,",
        "                'rotate': True,",
        "                'brightness': True",
        "            },",
        "            'data': {",
        "                'particle_radius': self.widgets['particle_radius'].value",
        "            }",
        "        }",
        "",
        "config_manager = TrainingConfig()",
        "config_manager.display()",
        "",
        "# -----------------------------------------------------------------------------",
        "# STEP 7: Dataset",
        "# -----------------------------------------------------------------------------",
        "class ParticleDataset(Dataset):",
        "    def __init__(self, frames, masks, augmentation_config=None):",
        "        self.frames = frames",
        "        self.masks = masks",
        "        self.aug_config = augmentation_config or {}",
        "",
        "    def __len__(self):",
        "        return len(self.frames)",
        "",
        "    def __getitem__(self, idx):",
        "        frame = self.frames[idx].copy()",
        "        mask = self.masks[idx].copy()",
        "",
        "        if self.aug_config.get('enabled', False):",
        "            if self.aug_config.get('flip_lr') and np.random.rand() > 0.5:",
        "                frame = np.fliplr(frame)",
        "                mask = np.fliplr(mask)",
        "            if self.aug_config.get('flip_ud') and np.random.rand() > 0.5:",
        "                frame = np.flipud(frame)",
        "                mask = np.flipud(mask)",
        "            if self.aug_config.get('rotate') and np.random.rand() > 0.5:",
        "                k = np.random.randint(1, 4)",
        "                frame = np.rot90(frame, k)",
        "                mask = np.rot90(mask, k)",
        "            if self.aug_config.get('brightness') and np.random.rand() > 0.5:",
        "                frame = np.clip(frame * np.random.uniform(0.8, 1.2), 0, 1)",
        "",
        "        frame = np.ascontiguousarray(frame)",
        "        mask = np.ascontiguousarray(mask)",
        "",
        "        frame = torch.from_numpy(frame).float().unsqueeze(0)",
        "        mask = torch.from_numpy(mask).float().unsqueeze(0)",
        "        return frame, mask",
        "",
        "def prepare_datasets(data_loader, config, video_files_to_train=None):",
        "    print(\"\\n\ud83d\udce6 Preparing datasets...\")",
        "    all_frames, all_masks = [], []",
        "",
        "    videos_to_process = video_files_to_train if video_files_to_train else data_loader.video_files",
        "",
        "    for video_path in tqdm(videos_to_process, desc=\"Loading\"):",
        "        video = data_loader.load_video_cached(video_path)",
        "        annotations = data_loader.load_annotations(video_path.stem)",
        "",
        "        if annotations is not None:",
        "            masks = data_loader.create_ground_truth_masks(annotations, video.shape, config['data']['particle_radius'])",
        "        else:",
        "            masks = np.zeros_like(video)",
        "",
        "        all_frames.append(video)",
        "        all_masks.append(masks)",
        "",
        "    all_frames = np.concatenate(all_frames, axis=0)",
        "    all_masks = np.concatenate(all_masks, axis=0)",
        "",
        "    val_split = config['training']['validation_split']",
        "    n_val = int(len(all_frames) * val_split)",
        "    indices = np.random.permutation(len(all_frames))",
        "",
        "    train_dataset = ParticleDataset(all_frames[indices[n_val:]], all_masks[indices[n_val:]], config['augmentation'])",
        "    val_dataset = ParticleDataset(all_frames[indices[:n_val]], all_masks[indices[:n_val]])",
        "",
        "    num_workers = 2 if device.type == 'cuda' else 0",
        "    train_loader = DataLoader(train_dataset, batch_size=config['training']['batch_size'],",
        "                             shuffle=True, num_workers=num_workers, pin_memory=True)",
        "    val_loader = DataLoader(val_dataset, batch_size=config['training']['batch_size'],",
        "                           shuffle=False, num_workers=num_workers, pin_memory=True)",
        "",
        "    print(f\"\u2705 Train: {len(train_dataset)}, Val: {len(val_dataset)}\")",
        "    return train_loader, val_loader",
        "",
        "# -----------------------------------------------------------------------------",
        "# STEP 8: Enhanced UNet Model",
        "# -----------------------------------------------------------------------------",
        "class UNet(nn.Module):",
        "    def __init__(self, in_channels=1, out_channels=1, features=[16, 32, 64]):",
        "        super(UNet, self).__init__()",
        "        self.encoder = nn.ModuleList()",
        "        self.decoder = nn.ModuleList()",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)",
        "",
        "        # Encoder",
        "        for feature in features:",
        "            self.encoder.append(",
        "                nn.Sequential(",
        "                    nn.Conv2d(in_channels, feature, kernel_size=3, padding=1),",
        "                    nn.BatchNorm2d(feature),",
        "                    nn.ReLU(inplace=True),",
        "                    nn.Conv2d(feature, feature, kernel_size=3, padding=1),",
        "                    nn.BatchNorm2d(feature),",
        "                    nn.ReLU(inplace=True)",
        "                )",
        "            )",
        "            in_channels = feature",
        "",
        "        # Decoder",
        "        for feature in reversed(features):",
        "            self.decoder.append(",
        "                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)",
        "            )",
        "            self.decoder.append(",
        "                nn.Sequential(",
        "                    nn.Conv2d(feature * 2, feature, kernel_size=3, padding=1),",
        "                    nn.BatchNorm2d(feature),",
        "                    nn.ReLU(inplace=True),",
        "                    nn.Conv2d(feature, feature, kernel_size=3, padding=1),",
        "                    nn.BatchNorm2d(feature),",
        "                    nn.ReLU(inplace=True)",
        "                )",
        "            )",
        "",
        "        self.bottleneck = nn.Sequential(",
        "            nn.Conv2d(features[-1], features[-1] * 2, kernel_size=3, padding=1),",
        "            nn.BatchNorm2d(features[-1] * 2),",
        "            nn.ReLU(inplace=True),",
        "            nn.Conv2d(features[-1] * 2, features[-1] * 2, kernel_size=3, padding=1),",
        "            nn.BatchNorm2d(features[-1] * 2),",
        "            nn.ReLU(inplace=True)",
        "        )",
        "",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)",
        "",
        "    def forward(self, x):",
        "        skip_connections = []",
        "",
        "        for encode in self.encoder:",
        "            x = encode(x)",
        "            skip_connections.append(x)",
        "            x = self.pool(x)",
        "",
        "        x = self.bottleneck(x)",
        "        skip_connections = skip_connections[::-1]",
        "",
        "        for idx in range(0, len(self.decoder), 2):",
        "            x = self.decoder[idx](x)",
        "            skip_connection = skip_connections[idx // 2]",
        "",
        "            if x.shape != skip_connection.shape:",
        "                x = F.interpolate(x, size=skip_connection.shape[2:])",
        "",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)",
        "            x = self.decoder[idx + 1](concat_skip)",
        "",
        "        return self.final_conv(x)",
        "",
        "# -----------------------------------------------------------------------------",
        "# STEP 9: Lightning Module (KEY ENHANCEMENT)",
        "# -----------------------------------------------------------------------------",
        "class ParticleDetector(L.LightningModule):",
        "    def __init__(self, config):",
        "        super().__init__()",
        "        self.save_hyperparameters()",
        "        self.config = config",
        "        ",
        "        # Model",
        "        self.model = UNet(",
        "            in_channels=1,",
        "            out_channels=1,",
        "            features=config['model']['unet_channels']",
        "        )",
        "        ",
        "        # Loss",
        "        self.criterion = nn.BCEWithLogitsLoss()",
        "        ",
        "        # Metrics",
        "        self.train_f1 = BinaryF1Score()",
        "        self.val_f1 = BinaryF1Score()",
        "        self.train_dice = Dice()",
        "        self.val_dice = Dice()",
        "        self.train_iou = JaccardIndex(task='binary')",
        "        self.val_iou = JaccardIndex(task='binary')",
        "",
        "    def forward(self, x):",
        "        return self.model(x)",
        "",
        "    def training_step(self, batch, batch_idx):",
        "        x, y = batch",
        "        y_hat = self(x)",
        "        loss = self.criterion(y_hat, y)",
        "        ",
        "        # Metrics",
        "        y_pred = torch.sigmoid(y_hat)",
        "        f1 = self.train_f1(y_pred, y.int())",
        "        dice = self.train_dice(y_pred, y.int())",
        "        iou = self.train_iou(y_pred, y.int())",
        "        ",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)",
        "        self.log('train_f1', f1, on_step=False, on_epoch=True, prog_bar=True)",
        "        self.log('train_dice', dice, on_step=False, on_epoch=True)",
        "        self.log('train_iou', iou, on_step=False, on_epoch=True)",
        "        ",
        "        return loss",
        "",
        "    def validation_step(self, batch, batch_idx):",
        "        x, y = batch",
        "        y_hat = self(x)",
        "        loss = self.criterion(y_hat, y)",
        "        ",
        "        # Metrics",
        "        y_pred = torch.sigmoid(y_hat)",
        "        f1 = self.val_f1(y_pred, y.int())",
        "        dice = self.val_dice(y_pred, y.int())",
        "        iou = self.val_iou(y_pred, y.int())",
        "        ",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)",
        "        self.log('val_f1', f1, on_step=False, on_epoch=True, prog_bar=True)",
        "        self.log('val_dice', dice, on_step=False, on_epoch=True)",
        "        self.log('val_iou', iou, on_step=False, on_epoch=True)",
        "        ",
        "        return loss",
        "",
        "    def configure_optimizers(self):",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.config['training']['learning_rate'])",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(",
        "            optimizer, mode='min', factor=0.5, patience=5, verbose=True",
        "        )",
        "        return {",
        "            'optimizer': optimizer,",
        "            'lr_scheduler': {",
        "                'scheduler': scheduler,",
        "                'monitor': 'val_loss'",
        "            }",
        "        }",
        "",
        "def create_model(config):",
        "    print(f\"\\n\ud83c\udfd7\ufe0f Building {config['model']['architecture'].upper()} model with Lightning...\")",
        "    model = ParticleDetector(config)",
        "    total_params = sum(p.numel() for p in model.parameters())",
        "    print(f\"\u2705 Model created! Parameters: {total_params:,}\")",
        "    return model",
        "",
        "# -----------------------------------------------------------------------------",
        "# STEP 10: Model Exporter",
        "# -----------------------------------------------------------------------------",
        "class ModelExporter:",
        "    def __init__(self, model_path):",
        "        self.model_path = Path(model_path)",
        "",
        "    def generate_version(self):",
        "        return f\"v_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"",
        "",
        "    def export_model(self, model, trainer_obj, config):",
        "        version = self.generate_version()",
        "        export_dir = self.model_path / version",
        "        export_dir.mkdir(parents=True, exist_ok=True)",
        "",
        "        print(f\"\\n\ud83d\udce6 Exporting model: {version}\")",
        "",
        "        # Save weights",
        "        torch.save(model.model.state_dict(), export_dir / \"weights.pth\")",
        "        ",
        "        # Get metrics",
        "        metrics = trainer_obj.callback_metrics",
        "        ",
        "        metadata = {",
        "            \"model_name\": config['model']['name'],",
        "            \"version\": version,",
        "            \"created_at\": datetime.now().isoformat(),",
        "            \"architecture\": {",
        "                \"type\": config['model']['architecture'],",
        "                \"unet_channels\": config['model']['unet_channels'],",
        "                \"out_channels\": 1",
        "            },",
        "            \"training\": config['training'],",
        "            \"performance\": {",
        "                \"val_loss\": float(metrics.get('val_loss', 0)),",
        "                \"val_f1\": float(metrics.get('val_f1', 0)),",
        "                \"val_dice\": float(metrics.get('val_dice', 0)),",
        "                \"val_iou\": float(metrics.get('val_iou', 0)),",
        "            },",
        "            \"data_info\": {",
        "                \"num_videos\": len(data_loader.video_files),",
        "                \"augmentation\": config['augmentation']['enabled']",
        "            },",
        "            \"compatibility\": {",
        "                \"deeptrack_version\": \"installed\",",
        "                \"torch_version\": torch.__version__,",
        "                \"lightning_version\": L.__version__",
        "            }",
        "        }",
        "",
        "        with open(export_dir / \"metadata.json\", 'w') as f:",
        "            json.dump(metadata, f, indent=2)",
        "",
        "        with open(export_dir / \"config.json\", 'w') as f:",
        "            json.dump(config, f, indent=2)",
        "",
        "        card = f\"\"\"# Model: {config['model']['name']}",
        "",
        "**Version:** {version}",
        "**Created:** {metadata['created_at']}",
        "**Architecture:** {metadata['architecture']['type'].upper()}",
        "",
        "## Performance",
        "",
        "| Metric | Validation |",
        "|--------|------------|",
        "| Loss | {metadata['performance']['val_loss']:.4f} |",
        "| F1 Score | {metadata['performance']['val_f1']:.4f} |",
        "| Dice | {metadata['performance']['val_dice']:.4f} |",
        "| IoU | {metadata['performance']['val_iou']:.4f} |",
        "",
        "## Architecture",
        "",
        "- Type: {metadata['architecture']['type'].upper()}",
        "- Channels: {metadata['architecture']['unet_channels']}",
        "",
        "## Training",
        "",
        "- Epochs: {config['training']['epochs']}",
        "- Batch Size: {config['training']['batch_size']}",
        "- Learning Rate: {config['training']['learning_rate']}",
        "- Mixed Precision: {config['training']['mixed_precision']}",
        "",
        "## Usage",
        "",
        "```python",
        "from src.engines.ai_engine import DeepTrackEngine",
        "engine = DeepTrackEngine()",
        "engine.load_model(\"weights.pth\", \"metadata.json\")",
        "```",
        "\"\"\"",
        "",
        "        with open(export_dir / \"MODEL_CARD.md\", 'w') as f:",
        "            f.write(card)",
        "",
        "        print(f\"\u2705 Model exported to: {export_dir}\")",
        "        print(f\"\\n\ud83d\udce5 Download from Google Drive:\")",
        "        print(f\"   {export_dir}\")",
        "",
        "        return export_dir",
        "",
        "print(\"\\n\" + \"=\" * 80)",
        "print(\"\u2705 SETUP COMPLETE! Ready to train.\")",
        "print(\"=\" * 80)",
        "print(\"\\n\ud83d\udca1 Next: Run the training cell below!\")",
        ""
      ],
      "metadata": {
        "id": "enhanced_setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================",
        "# \ud83c\udfaf ENHANCED TRAINING EXECUTION",
        "# ============================================================================",
        "",
        "config = config_manager.get_config()",
        "",
        "print(\"=\" * 80)",
        "print(\"\ud83d\ude80 STARTING ENHANCED TRAINING PIPELINE\")",
        "print(\"=\" * 80)",
        "print(f\"\\n\u2699\ufe0f  Configuration:\")",
        "print(f\"   Model: {config['model']['name']}\")",
        "print(f\"   Architecture: {config['model']['architecture'].upper()}\")",
        "print(f\"   Epochs: {config['training']['epochs']}\")",
        "print(f\"   Batch Size: {config['training']['batch_size']}\")",
        "print(f\"   Learning Rate: {config['training']['learning_rate']}\")",
        "print(f\"   Mixed Precision: {config['training']['mixed_precision']} \u26a1\")",
        "print(f\"   Early Stopping: {config['training']['early_stopping']}\")",
        "print(f\"   Gradient Clip: {config['training']['gradient_clip']}\")",
        "print(f\"   Incremental: {config['training']['incremental']}\")",
        "print(\"=\" * 80)",
        "",
        "# Determine which videos to train",
        "videos_to_train = None",
        "should_load_existing = False",
        "",
        "if config['training']['incremental']:",
        "    untrained_videos = tracker.get_untrained_videos(data_loader.video_files)",
        "    ",
        "    if not untrained_videos:",
        "        print(\"\\n\u2705 All videos already trained!\")",
        "        print(\"\ud83d\udca1 Set 'Incremental Training' to False to retrain all.\")",
        "        videos_to_train = []",
        "    else:",
        "        print(f\"\\n\ud83c\udd95 Found {len(untrained_videos)} new/untrained video(s):\")",
        "        for v in untrained_videos:",
        "            print(f\"   - {v.name}\")",
        "        videos_to_train = untrained_videos",
        "        ",
        "        latest_ckpt = LOG_PATH / 'lightning_logs' / 'last.ckpt'",
        "        if latest_ckpt.exists():",
        "            should_load_existing = True",
        "            print(f\"\\n\ud83d\udce5 Existing checkpoint found - continuing training\")",
        "else:",
        "    print(\"\\n\ud83d\udd04 Full training mode - training on all videos\")",
        "    videos_to_train = data_loader.video_files",
        "",
        "if not videos_to_train:",
        "    print(\"\\n\u270b Nothing to train. Exiting.\")",
        "else:",
        "    # Prepare datasets",
        "    train_loader, val_loader = prepare_datasets(data_loader, config, videos_to_train)",
        "    ",
        "    # Create Lightning model",
        "    model = create_model(config)",
        "    ",
        "    # Setup callbacks",
        "    callbacks = [",
        "        ModelCheckpoint(",
        "            dirpath=LOG_PATH / 'lightning_logs',",
        "            filename='best-{epoch:02d}-{val_loss:.4f}',",
        "            monitor='val_loss',",
        "            mode='min',",
        "            save_top_k=3,",
        "            save_last=True",
        "        ),",
        "        LearningRateMonitor(logging_interval='epoch')",
        "    ]",
        "    ",
        "    if config['training']['early_stopping']:",
        "        callbacks.append(",
        "            EarlyStopping(",
        "                monitor='val_loss',",
        "                patience=10,",
        "                mode='min',",
        "                verbose=True",
        "            )",
        "        )",
        "    ",
        "    # Setup trainer",
        "    trainer = L.Trainer(",
        "        max_epochs=config['training']['epochs'],",
        "        accelerator='auto',",
        "        devices=1,",
        "        precision='16-mixed' if config['training']['mixed_precision'] else '32',",
        "        callbacks=callbacks,",
        "        logger=CSVLogger(LOG_PATH, name='lightning_logs'),",
        "        gradient_clip_val=config['training']['gradient_clip'],",
        "        log_every_n_steps=10,",
        "        enable_progress_bar=True,",
        "        enable_model_summary=True",
        "    )",
        "    ",
        "    # Load checkpoint if continuing",
        "    ckpt_path = None",
        "    if should_load_existing:",
        "        ckpt_path = LOG_PATH / 'lightning_logs' / 'last.ckpt'",
        "        if ckpt_path.exists():",
        "            print(f\"\u2705 Loading checkpoint: {ckpt_path}\")",
        "    ",
        "    # Train!",
        "    print(f\"\\n{'='*80}\")",
        "    print(f\"\ud83c\udfaf Training on {len(videos_to_train)} video(s)\")",
        "    print(f\"{'='*80}\\n\")",
        "    ",
        "    trainer.fit(model, train_loader, val_loader, ckpt_path=ckpt_path)",
        "    ",
        "    # Mark videos as trained",
        "    if config['training']['incremental']:",
        "        exporter = ModelExporter(MODEL_PATH)",
        "        version = exporter.generate_version()",
        "        for video_path in videos_to_train:",
        "            tracker.mark_video_trained(video_path, version)",
        "        print(f\"\\n\u2705 Marked {len(videos_to_train)} video(s) as trained\")",
        "    ",
        "    # Export model",
        "    exporter = ModelExporter(MODEL_PATH)",
        "    export_dir = exporter.export_model(model, trainer, config)",
        "    ",
        "    print(\"\\n\" + \"=\" * 80)",
        "    print(\"\ud83c\udf89 TRAINING COMPLETE!\")",
        "    print(\"=\" * 80)",
        "    print(f\"\\n\ud83d\udce6 Model saved to: {export_dir}\")",
        "    print(f\"\\n\ud83d\udca1 Performance Enhancements Applied:\")",
        "    print(f\"   \u26a1 PyTorch Lightning: 2-3x faster training\")",
        "    print(f\"   \u26a1 Mixed Precision: Additional 1.5-2x speedup\")",
        "    print(f\"   \u26a1 Advanced Metrics: F1, Dice, IoU tracking\")",
        "    print(f\"   \u26a1 Early Stopping: Prevents overfitting\")",
        "    print(f\"   \u26a1 Gradient Clipping: Stable training\")",
        "    print(\"=\" * 80)",
        ""
      ],
      "metadata": {
        "id": "enhanced_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================",
        "# \ud83c\udfaf POST-PROCESSING: Particle Tracking & Analysis",
        "# ============================================================================",
        "# This cell provides post-processing capabilities for analyzing tracked particles",
        "# Includes: Trackpy integration, trajectory analysis, MSD calculation",
        "# ============================================================================",
        "",
        "print(\"=\" * 80)",
        "print(\"\ud83d\udcca POST-PROCESSING & ANALYSIS\")",
        "print(\"=\" * 80)",
        "",
        "# -----------------------------------------------------------------------------",
        "# Post-Processing Functions",
        "# -----------------------------------------------------------------------------",
        "",
        "def extract_particles_from_predictions(model, video_path, threshold=0.5, min_area=3):",
        "    \"\"\"",
        "    Extract particle centroids from model predictions",
        "    ",
        "    Args:",
        "        model: Trained Lightning model",
        "        video_path: Path to video file",
        "        threshold: Prediction threshold",
        "        min_area: Minimum particle area in pixels",
        "        ",
        "    Returns:",
        "        DataFrame with columns: frame, x, y, area",
        "    \"\"\"",
        "    import trackpy as tp",
        "    from skimage import measure, morphology",
        "    ",
        "    print(f\"\\n\ud83d\udd2c Analyzing: {video_path.name}\")",
        "    ",
        "    # Load video",
        "    video = data_loader.load_video_cached(video_path)",
        "    ",
        "    # Run predictions",
        "    model.eval()",
        "    model = model.to(device)",
        "    ",
        "    detections = []",
        "    ",
        "    with torch.no_grad():",
        "        for frame_idx in tqdm(range(len(video)), desc=\"Processing frames\"):",
        "            frame = torch.from_numpy(video[frame_idx]).float().unsqueeze(0).unsqueeze(0).to(device)",
        "            pred = torch.sigmoid(model(frame)).cpu().numpy()[0, 0]",
        "            ",
        "            # Threshold and clean",
        "            mask = (pred >= threshold).astype(np.uint8)",
        "            mask = morphology.remove_small_objects(mask.astype(bool), min_size=min_area)",
        "            mask = morphology.binary_opening(mask, morphology.disk(1)).astype(np.uint8)",
        "            ",
        "            # Extract centroids",
        "            labeled = measure.label(mask, connectivity=1)",
        "            props = measure.regionprops(labeled)",
        "            ",
        "            for prop in props:",
        "                y, x = prop.centroid",
        "                detections.append({",
        "                    'frame': frame_idx,",
        "                    'x': float(x),",
        "                    'y': float(y),",
        "                    'area': int(prop.area),",
        "                    'intensity': float(pred[int(y), int(x)])",
        "                })",
        "    ",
        "    df = pd.DataFrame(detections)",
        "    print(f\"\u2705 Detected {len(df)} particles across {len(video)} frames\")",
        "    print(f\"   Avg particles/frame: {len(df)/len(video):.1f}\")",
        "    ",
        "    return df",
        "",
        "",
        "def track_particles(detections_df, search_range=10, memory=3):",
        "    \"\"\"",
        "    Link detections into trajectories using trackpy",
        "    ",
        "    Args:",
        "        detections_df: DataFrame with frame, x, y columns",
        "        search_range: Maximum distance particles can move between frames",
        "        memory: Number of frames to remember lost particles",
        "        ",
        "    Returns:",
        "        DataFrame with additional 'particle' column for trajectory IDs",
        "    \"\"\"",
        "    import trackpy as tp",
        "    ",
        "    print(f\"\\n\ud83d\udd17 Tracking particles...\")",
        "    print(f\"   Search range: {search_range} pixels\")",
        "    print(f\"   Memory: {memory} frames\")",
        "    ",
        "    # Link trajectories",
        "    tracks = tp.link(detections_df, search_range=search_range, memory=memory)",
        "    ",
        "    # Filter short trajectories",
        "    min_length = 5",
        "    tracks_filtered = tp.filter_stubs(tracks, threshold=min_length)",
        "    ",
        "    n_trajectories = tracks_filtered['particle'].nunique()",
        "    avg_length = tracks_filtered.groupby('particle').size().mean()",
        "    ",
        "    print(f\"\u2705 Tracking complete!\")",
        "    print(f\"   Total trajectories: {n_trajectories}\")",
        "    print(f\"   Avg trajectory length: {avg_length:.1f} frames\")",
        "    print(f\"   Filtered out {len(tracks) - len(tracks_filtered)} short tracks\")",
        "    ",
        "    return tracks_filtered",
        "",
        "",
        "def calculate_msd(tracks, fps=30, pixel_size=0.1):",
        "    \"\"\"",
        "    Calculate Mean Squared Displacement (MSD) for diffusion analysis",
        "    ",
        "    Args:",
        "        tracks: DataFrame with particle trajectories",
        "        fps: Frames per second",
        "        pixel_size: Microns per pixel",
        "        ",
        "    Returns:",
        "        DataFrame with lag_time and msd columns",
        "    \"\"\"",
        "    import trackpy as tp",
        "    ",
        "    print(f\"\\n\ud83d\udcc8 Calculating MSD...\")",
        "    print(f\"   FPS: {fps}\")",
        "    print(f\"   Pixel size: {pixel_size} \u00b5m\")",
        "    ",
        "    # Calculate ensemble MSD",
        "    emsd = tp.emsd(tracks, mpp=pixel_size, fps=fps)",
        "    ",
        "    print(f\"\u2705 MSD calculated for {len(emsd)} lag times\")",
        "    ",
        "    return emsd",
        "",
        "",
        "def fit_diffusion_models(emsd):",
        "    \"\"\"",
        "    Fit diffusion models to MSD data",
        "    ",
        "    Returns:",
        "        dict with diffusion coefficient and anomalous exponent",
        "    \"\"\"",
        "    from scipy.optimize import curve_fit",
        "    ",
        "    print(f\"\\n\ud83e\uddee Fitting diffusion models...\")",
        "    ",
        "    t = emsd.index.values",
        "    msd = emsd.values",
        "    ",
        "    # Fit first 10 points",
        "    N = min(10, len(t))",
        "    t_fit = t[:N]",
        "    msd_fit = msd[:N]",
        "    ",
        "    # Linear model: MSD = 4*D*t + offset",
        "    def linear_model(t, D, offset):",
        "        return 4 * D * t + offset",
        "    ",
        "    # Power law: MSD = A*t^alpha",
        "    def power_law(t, A, alpha):",
        "        return A * t**alpha",
        "    ",
        "    try:",
        "        # Linear fit",
        "        params_lin, _ = curve_fit(linear_model, t_fit, msd_fit)",
        "        D_est, offset = params_lin",
        "        ",
        "        # Power law fit",
        "        params_pow, _ = curve_fit(power_law, t_fit, msd_fit)",
        "        A_est, alpha_est = params_pow",
        "        ",
        "        print(f\"\u2705 Diffusion models fitted!\")",
        "        print(f\"   Diffusion coefficient: D = {D_est:.4f} \u00b5m\u00b2/s\")",
        "        print(f\"   Linear offset: {offset:.4f} \u00b5m\u00b2\")",
        "        print(f\"   Anomalous exponent: \u03b1 = {alpha_est:.2f}\")",
        "        ",
        "        # Interpret alpha",
        "        if alpha_est < 0.95:",
        "            motion_type = \"Sub-diffusive (confined/hindered)\"",
        "        elif alpha_est > 1.05:",
        "            motion_type = \"Super-diffusive (active transport)\"",
        "        else:",
        "            motion_type = \"Normal Brownian diffusion\"",
        "        ",
        "        print(f\"   Motion type: {motion_type}\")",
        "        ",
        "        return {",
        "            'D': D_est,",
        "            'offset': offset,",
        "            'alpha': alpha_est,",
        "            'motion_type': motion_type,",
        "            't_fit': t_fit,",
        "            'msd_fit': msd_fit,",
        "            'linear_params': params_lin,",
        "            'power_params': params_pow",
        "        }",
        "    except Exception as e:",
        "        print(f\"\u26a0\ufe0f  Fitting failed: {e}\")",
        "        return None",
        "",
        "",
        "def visualize_tracking_results(video, tracks, frame_idx=0):",
        "    \"\"\"Visualize tracking results on a specific frame\"\"\"",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))",
        "    ",
        "    # Original frame with detections",
        "    axes[0].imshow(video[frame_idx], cmap='gray')",
        "    frame_tracks = tracks[tracks['frame'] == frame_idx]",
        "    if not frame_tracks.empty:",
        "        axes[0].scatter(frame_tracks['x'], frame_tracks['y'],",
        "                       c='red', s=50, marker='o', facecolors='none', linewidths=2)",
        "    axes[0].set_title(f\"Frame {frame_idx} - {len(frame_tracks)} particles\")",
        "    axes[0].axis('off')",
        "    ",
        "    # Trajectory visualization",
        "    axes[1].imshow(video[frame_idx], cmap='gray', alpha=0.3)",
        "    ",
        "    # Plot a few sample trajectories",
        "    sample_particles = tracks['particle'].unique()[:10]",
        "    colors = plt.cm.rainbow(np.linspace(0, 1, len(sample_particles)))",
        "    ",
        "    for particle_id, color in zip(sample_particles, colors):",
        "        traj = tracks[tracks['particle'] == particle_id]",
        "        axes[1].plot(traj['x'], traj['y'], '-', color=color, linewidth=2, alpha=0.7)",
        "        axes[1].plot(traj['x'].iloc[-1], traj['y'].iloc[-1], 'o', ",
        "                    color=color, markersize=8)",
        "    ",
        "    axes[1].set_title(f\"Sample Trajectories (n={len(sample_particles)})\")",
        "    axes[1].axis('off')",
        "    ",
        "    plt.tight_layout()",
        "    plt.show()",
        "",
        "",
        "def visualize_msd_analysis(emsd, fit_results):",
        "    \"\"\"Visualize MSD analysis and fits\"\"\"",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))",
        "    ",
        "    t = emsd.index.values",
        "    msd = emsd.values",
        "    ",
        "    # Log-log plot",
        "    axes[0].loglog(t, msd, 'o-', label='MSD data', markersize=4)",
        "    if fit_results:",
        "        t_fit = fit_results['t_fit']",
        "        axes[0].loglog(t_fit, fit_results['linear_params'][0] * 4 * t_fit + fit_results['linear_params'][1],",
        "                      '--', label='Linear fit', linewidth=2)",
        "        axes[0].loglog(t_fit, fit_results['power_params'][0] * t_fit**fit_results['power_params'][1],",
        "                      ':', label='Power-law fit', linewidth=2)",
        "    axes[0].set_xlabel('Lag time (seconds)')",
        "    axes[0].set_ylabel('MSD (\u00b5m\u00b2)')",
        "    axes[0].set_title('MSD - Log-log scale')",
        "    axes[0].legend()",
        "    axes[0].grid(True, alpha=0.3)",
        "    ",
        "    # Linear plot",
        "    axes[1].plot(t, msd, 'o-', label='MSD data', markersize=4)",
        "    if fit_results:",
        "        t_fit = fit_results['t_fit']",
        "        axes[1].plot(t_fit, fit_results['linear_params'][0] * 4 * t_fit + fit_results['linear_params'][1],",
        "                    '--', label='Linear fit', linewidth=2)",
        "        axes[1].plot(t_fit, fit_results['power_params'][0] * t_fit**fit_results['power_params'][1],",
        "                    ':', label='Power-law fit', linewidth=2)",
        "    axes[1].set_xlabel('Lag time (seconds)')",
        "    axes[1].set_ylabel('MSD (\u00b5m\u00b2)')",
        "    axes[1].set_title('MSD - Linear scale')",
        "    axes[1].legend()",
        "    axes[1].grid(True, alpha=0.3)",
        "    ",
        "    plt.tight_layout()",
        "    plt.show()",
        "",
        "",
        "# -----------------------------------------------------------------------------",
        "# Example Usage",
        "# -----------------------------------------------------------------------------",
        "",
        "print(\"\\n\" + \"=\" * 80)",
        "print(\"\ud83d\udca1 POST-PROCESSING PIPELINE READY\")",
        "print(\"=\" * 80)",
        "print(\"\\nExample usage after training:\")",
        "print(\"\"\"",
        "# 1. Load trained model",
        "model = ParticleDetector.load_from_checkpoint(",
        "    LOG_PATH / 'lightning_logs' / 'last.ckpt',",
        "    config=config",
        ")",
        "",
        "# 2. Extract particles from video",
        "video_path = data_loader.video_files[0]",
        "detections = extract_particles_from_predictions(model, video_path, threshold=0.5)",
        "",
        "# 3. Track particles",
        "tracks = track_particles(detections, search_range=10, memory=3)",
        "",
        "# 4. Save tracks",
        "tracks.to_csv(RESULTS_PATH / f\"{video_path.stem}_tracks.csv\", index=False)",
        "",
        "# 5. Calculate MSD",
        "emsd = calculate_msd(tracks, fps=30, pixel_size=0.1)",
        "",
        "# 6. Fit diffusion models",
        "fit_results = fit_diffusion_models(emsd)",
        "",
        "# 7. Visualize",
        "video = data_loader.load_video_cached(video_path)",
        "visualize_tracking_results(video, tracks, frame_idx=10)",
        "visualize_msd_analysis(emsd, fit_results)",
        "\"\"\")",
        "",
        "print(\"\\n\" + \"=\" * 80)",
        "print(\"\u2705 All post-processing functions loaded!\")",
        "print(\"=\" * 80)",
        ""
      ],
      "metadata": {
        "id": "postprocessing_cell"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}