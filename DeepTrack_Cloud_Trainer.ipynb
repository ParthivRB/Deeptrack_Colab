{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2I0AvTdjM441/Q5hVbCb1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthivRB/Deeptrack_Colab/blob/main/DeepTrack_Cloud_Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# üéØ DeepTrack2 Cloud Training System - Complete Notebook\n",
        "# ============================================================================\n",
        "# One-stop solution for training particle tracking models in the cloud\n",
        "# Version: 1.0.0 | Compatible with DeepTrack MPT Studio\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üöÄ DEEPTRACK CLOUD TRAINER\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nInitializing training environment.. .\\n\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 1: Install Dependencies\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = [\n",
        "    'deeptrack', 'deeplay', 'torch', 'torchvision',\n",
        "    'tqdm', 'ipywidgets', 'matplotlib', 'scikit-image',\n",
        "    'pandas', 'scipy'\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "\n",
        "print(\"‚úÖ All dependencies installed!\\n\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 2: Import Libraries\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"üìö Loading libraries...\")\n",
        "\n",
        "import os\n",
        "import json\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy. ndimage import label, center_of_mass\n",
        "from skimage import io as skio\n",
        "from tqdm. auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import deeplay as dl\n",
        "import deeptrack as dt\n",
        "import importlib.metadata\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"‚úÖ Libraries loaded!\")\n",
        "print(f\"üñ•Ô∏è  Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"   PyTorch:  {torch.__version__}\")\n",
        "try:\n",
        "    dt_version = importlib.metadata.version('deeptrack')\n",
        "except importlib.metadata.PackageNotFoundError:\n",
        "    dt_version = \"Unknown (Package Not Found)\"\n",
        "print(f\"   DeepTrack: {dt_version}\\n\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 3: Mount Google Drive\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"üìÇ Mounting Google Drive...\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "BASE_PATH = Path('/content/drive/MyDrive/DeepTrack_Studio')\n",
        "DATA_PATH = BASE_PATH / 'training_data'\n",
        "MODEL_PATH = BASE_PATH / 'models'\n",
        "LOG_PATH = BASE_PATH / 'logs'\n",
        "\n",
        "for path in [BASE_PATH, DATA_PATH, MODEL_PATH, LOG_PATH]:\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "(DATA_PATH / 'videos').mkdir(exist_ok=True)\n",
        "(DATA_PATH / 'annotations').mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Google Drive ready!\")\n",
        "print(f\"   Base:  {BASE_PATH}\\n\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 4: Data Loader\n",
        "# -----------------------------------------------------------------------------\n",
        "class TrainingDataLoader:\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = Path(data_path)\n",
        "        self.videos_path = self.data_path / 'videos'\n",
        "        self.annotations_path = self.data_path / 'annotations'\n",
        "        self.video_files = []\n",
        "        self.annotation_files = {}\n",
        "\n",
        "    def scan_data(self):\n",
        "        print(\"üîç Scanning for training data...\")\n",
        "        video_extensions = ['.tif', '.tiff', '.png', '.jpg']\n",
        "        self.video_files = []\n",
        "        for ext in video_extensions:\n",
        "            self.video_files.extend(list(self.videos_path.glob(f\"*{ext}\")))\n",
        "\n",
        "        if not self.video_files:\n",
        "            print(f\"‚ùå No videos found!\")\n",
        "            print(f\"\\nüìù UPLOAD INSTRUCTIONS:\")\n",
        "            print(f\"   1. Open Google Drive in new tab\")\n",
        "            print(f\"   2. Go to: {self.videos_path}\")\n",
        "            print(f\"   3. Upload your . tif video files\")\n",
        "            print(f\"   4. Return here and re-run this cell\")\n",
        "            return False\n",
        "\n",
        "        print(f\"‚úÖ Found {len(self.video_files)} video(s)\")\n",
        "\n",
        "        self.annotation_files = {}\n",
        "        for video_path in self.video_files:\n",
        "            annotation_path = self.annotations_path / f\"{video_path.stem}_particles.csv\"\n",
        "            if annotation_path. exists():\n",
        "                self.annotation_files[video_path. stem] = annotation_path\n",
        "\n",
        "        print(f\"üìã Found {len(self.annotation_files)} annotation(s)\")\n",
        "        for i, video_path in enumerate(self.video_files, 1):\n",
        "            status = \"‚úÖ\" if video_path.stem in self.annotation_files else \"‚ö†Ô∏è (no annotation)\"\n",
        "            print(f\"   {i}. {video_path.name} {status}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def load_video(self, video_path):\n",
        "        video = skio.imread(str(video_path))\n",
        "        if video.ndim == 2:\n",
        "            video = video[np.newaxis, ...]\n",
        "        elif video.ndim == 4:\n",
        "            video = video[:, 0, : , :]\n",
        "        if video.max() > 0:\n",
        "            video = video. astype(np.float32) / video.max()\n",
        "        return video\n",
        "\n",
        "    def load_annotations(self, video_stem):\n",
        "        if video_stem not in self.annotation_files:\n",
        "            return None\n",
        "        df = pd.read_csv(self.annotation_files[video_stem])\n",
        "        return df\n",
        "\n",
        "    def create_ground_truth_masks(self, annotations, shape, radius=3):\n",
        "        num_frames, height, width = shape\n",
        "        masks = np.zeros(shape, dtype=np.float32)\n",
        "        yy, xx = np.ogrid[: height, :width]\n",
        "        for frame_idx in range(num_frames):\n",
        "            frame_particles = annotations[annotations['frame'] == frame_idx]\n",
        "            for _, particle in frame_particles.iterrows():\n",
        "                x, y = particle['x'], particle['y']\n",
        "                distance = (xx - x)**2 + (yy - y)**2\n",
        "                masks[frame_idx][distance <= radius**2] = 1.0\n",
        "        return masks\n",
        "\n",
        "    def preview_data(self, video_idx=0, frame_idx=0):\n",
        "        if not self.video_files:\n",
        "            return\n",
        "        video_path = self.video_files[video_idx]\n",
        "        video = self.load_video(video_path)\n",
        "        annotations = self.load_annotations(video_path.stem)\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        axes[0].imshow(video[frame_idx], cmap='gray')\n",
        "        axes[0].set_title(f\"{video_path.name} - Frame {frame_idx}\")\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        axes[1].imshow(video[frame_idx], cmap='gray')\n",
        "        if annotations is not None:\n",
        "            frame_particles = annotations[annotations['frame'] == frame_idx]\n",
        "            if not frame_particles.empty:\n",
        "                axes[1].scatter(frame_particles['x'], frame_particles['y'],\n",
        "                              c='red', s=50, marker='o', facecolors='none', linewidths=2)\n",
        "            axes[1].set_title(f\"Annotations ({len(frame_particles)} particles)\")\n",
        "        else:\n",
        "            axes[1].set_title(\"No annotations\")\n",
        "        axes[1].axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "data_loader = TrainingDataLoader(DATA_PATH)\n",
        "data_available = data_loader.scan_data()\n",
        "\n",
        "if data_available:\n",
        "    print(\"\\nüì∏ Preview:\")\n",
        "    data_loader.preview_data(video_idx=0, frame_idx=0)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 5: Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "class TrainingConfig:\n",
        "    def __init__(self):\n",
        "        self.widgets = {}\n",
        "        self.widgets['model_name'] = widgets.Text(value='particle_detector', description='Model Name:')\n",
        "        self.widgets['architecture'] = widgets. Dropdown(options=['UNet'], value='UNet', description='Architecture:')\n",
        "        self.widgets['unet_channels'] = widgets.Text(value='16,32,64', description='Channels:')\n",
        "        self.widgets['epochs'] = widgets.IntSlider(value=30, min=10, max=100, description='Epochs:')\n",
        "        self.widgets['batch_size'] = widgets. Dropdown(options=[2,4,8], value=4, description='Batch Size:')\n",
        "        self.widgets['learning_rate'] = widgets.FloatLogSlider(value=1e-4, base=10, min=-6, max=-2, description='Learning Rate:')\n",
        "        self.widgets['validation_split'] = widgets.FloatSlider(value=0.2, min=0.1, max=0.4, description='Val Split:')\n",
        "        self.widgets['augmentation'] = widgets.Checkbox(value=True, description='Augmentation')\n",
        "        self.widgets['particle_radius'] = widgets.IntSlider(value=3, min=1, max=10, description='Particle Radius:')\n",
        "\n",
        "    def display(self):\n",
        "        display(HTML(\"<h3>‚öôÔ∏è Training Configuration</h3>\"))\n",
        "        display(widgets.VBox([\n",
        "            self.widgets['model_name'],\n",
        "            self.widgets['architecture'],\n",
        "            self.widgets['unet_channels'],\n",
        "            self.widgets['epochs'],\n",
        "            self.widgets['batch_size'],\n",
        "            self. widgets['learning_rate'],\n",
        "            self.widgets['validation_split'],\n",
        "            self.widgets['augmentation'],\n",
        "            self.widgets['particle_radius']\n",
        "        ]))\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            'model':  {\n",
        "                'name': self.widgets['model_name'].value,\n",
        "                'architecture': self.widgets['architecture'].value. lower(),\n",
        "                'unet_channels': [int(x. strip()) for x in self.widgets['unet_channels'].value. split(',')]\n",
        "            },\n",
        "            'training':  {\n",
        "                'epochs': self. widgets['epochs'].value,\n",
        "                'batch_size': self.widgets['batch_size'].value,\n",
        "                'learning_rate':  self.widgets['learning_rate']. value,\n",
        "                'validation_split': self.widgets['validation_split'].value\n",
        "            },\n",
        "            'augmentation':  {\n",
        "                'enabled': self.widgets['augmentation'].value,\n",
        "                'flip_lr': True,\n",
        "                'flip_ud':  True,\n",
        "                'rotate': True,\n",
        "                'brightness': True\n",
        "            },\n",
        "            'data': {\n",
        "                'particle_radius': self.widgets['particle_radius'].value\n",
        "            }\n",
        "        }\n",
        "\n",
        "config_manager = TrainingConfig()\n",
        "config_manager.display()\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 6: Dataset\n",
        "# -----------------------------------------------------------------------------\n",
        "class ParticleDataset(Dataset):\n",
        "    def __init__(self, frames, masks, augmentation_config=None):\n",
        "        self.frames = frames\n",
        "        self.masks = masks\n",
        "        self.aug_config = augmentation_config or {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame = self.frames[idx]. copy()\n",
        "        mask = self.masks[idx].copy()\n",
        "\n",
        "        if self.aug_config. get('enabled', False):\n",
        "            if self.aug_config. get('flip_lr') and np.random.rand() > 0.5:\n",
        "                frame = np.fliplr(frame)\n",
        "                mask = np.fliplr(mask)\n",
        "            if self.aug_config.get('flip_ud') and np.random.rand() > 0.5:\n",
        "                frame = np.flipud(frame)\n",
        "                mask = np.flipud(mask)\n",
        "            if self.aug_config. get('rotate') and np.random.rand() > 0.5:\n",
        "                k = np.random.randint(1, 4)\n",
        "                frame = np.rot90(frame, k)\n",
        "                mask = np.rot90(mask, k)\n",
        "            if self.aug_config.get('brightness') and np.random.rand() > 0.5:\n",
        "                frame = np.clip(frame * np.random.uniform(0.8, 1.2), 0, 1)\n",
        "\n",
        "        frame = torch.from_numpy(frame).float().unsqueeze(0)\n",
        "        mask = torch.from_numpy(mask).float().unsqueeze(0)\n",
        "        return frame, mask\n",
        "\n",
        "def prepare_datasets(data_loader, config):\n",
        "    print(\"\\nüì¶ Preparing datasets...\")\n",
        "    all_frames, all_masks = [], []\n",
        "\n",
        "    for video_path in tqdm(data_loader.video_files, desc=\"Loading\"):\n",
        "        video = data_loader. load_video(video_path)\n",
        "        annotations = data_loader.load_annotations(video_path.stem)\n",
        "\n",
        "        if annotations is not None:\n",
        "            masks = data_loader.create_ground_truth_masks(annotations, video.shape, config['data']['particle_radius'])\n",
        "        else:\n",
        "            masks = np. zeros_like(video)\n",
        "\n",
        "        all_frames.append(video)\n",
        "        all_masks.append(masks) # This was the indentation error\n",
        "\n",
        "    all_frames = np.concatenate(all_frames, axis=0)\n",
        "    all_masks = np.concatenate(all_masks, axis=0)\n",
        "\n",
        "    val_split = config['training']['validation_split']\n",
        "    n_val = int(len(all_frames) * val_split)\n",
        "    indices = np.random.permutation(len(all_frames))\n",
        "\n",
        "    train_dataset = ParticleDataset(all_frames[indices[n_val:]], all_masks[indices[n_val:]], config['augmentation'])\n",
        "    val_dataset = ParticleDataset(all_frames[indices[:n_val]], all_masks[indices[:n_val]])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config['training']['batch_size'], shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config['training']['batch_size'], shuffle=False, num_workers=2)\n",
        "\n",
        "    print(f\"‚úÖ Train:  {len(train_dataset)}, Val: {len(val_dataset)}\")\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 7: Model\n",
        "# -----------------------------------------------------------------------------\n",
        "def create_model(config):\n",
        "    print(f\"\\nüèóÔ∏è Building {config['model']['architecture']. upper()} model...\")\n",
        "    unet_channels_list = config['model']['unet_channels']\n",
        "    if not unet_channels_list:\n",
        "        base_channels = 16\n",
        "        depth = 3\n",
        "    else:\n",
        "        base_channels = unet_channels_list[0]\n",
        "        # The deeplay.UNet2d constructor expects 'channels' to be a list\n",
        "        # and infers depth from its length, not a separate 'depth' argument.\n",
        "\n",
        "    model = dl.UNet2d(\n",
        "        in_channels=1,\n",
        "        out_channels=1,\n",
        "        channels=unet_channels_list # Pass the list directly here\n",
        "    )\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"‚úÖ Model created!  Parameters: {total_params:,}\")\n",
        "    return model\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 8:  Trainer\n",
        "# -----------------------------------------------------------------------------\n",
        "class Trainer:\n",
        "    def __init__(self, model, config, save_dir):\n",
        "        self.model = model. to(device)\n",
        "        self.config = config\n",
        "        self.save_dir = Path(save_dir)\n",
        "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.history = {'train_loss': [], 'val_loss': [], 'train_iou': [], 'val_iou': []}\n",
        "        self.best_val_loss = float('inf')\n",
        "\n",
        "    def _calculate_iou(self, pred, target, threshold=0.5):\n",
        "        pred_binary = (pred > threshold).float()\n",
        "        target_binary = (target > threshold).float()\n",
        "        intersection = (pred_binary * target_binary).sum()\n",
        "        union = pred_binary.sum() + target_binary.sum() - intersection\n",
        "        return (intersection / union).item() if union > 0 else 1.0\n",
        "\n",
        "    def train_epoch(self, train_loader):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        total_iou = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=\"Training\")\n",
        "        for frames, masks in pbar:\n",
        "            frames, masks = frames.to(device), masks.to(device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(frames)\n",
        "            loss = self.criterion(outputs, masks)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                iou = self._calculate_iou(torch.sigmoid(outputs), masks)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_iou += iou\n",
        "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'iou': f\"{iou:.4f}\"})\n",
        "\n",
        "        return total_loss / len(train_loader), total_iou / len(train_loader)\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        total_iou = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for frames, masks in tqdm(val_loader, desc=\"Validation\"):\n",
        "                frames, masks = frames.to(device), masks.to(device)\n",
        "                outputs = self.model(frames)\n",
        "                loss = self.criterion(outputs, masks)\n",
        "                iou = self._calculate_iou(torch.sigmoid(outputs), masks)\n",
        "                total_loss += loss.item()\n",
        "                total_iou += iou\n",
        "\n",
        "        return total_loss / len(val_loader), total_iou / len(val_loader)\n",
        "\n",
        "    def save_checkpoint(self, epoch, is_best=False):\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'history': self.history,\n",
        "            'config': self.config\n",
        "        }\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            torch.save(checkpoint, self.save_dir / f\"checkpoint_epoch{epoch}.pth\")\n",
        "\n",
        "        if is_best:\n",
        "            torch.save(checkpoint, self. save_dir / \"best_model.pth\")\n",
        "            print(f\"   üíæ Best model saved (loss: {self.best_val_loss:.4f})\")\n",
        "\n",
        "    def plot_progress(self):\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "        axes[0].plot(self.history['train_loss'], label='Train', marker='o')\n",
        "        axes[0].plot(self.history['val_loss'], label='Val', marker='s')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Loss')\n",
        "        axes[0].set_title('Loss')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True)\n",
        "\n",
        "        axes[1].plot(self.history['train_iou'], label='Train', marker='o')\n",
        "        axes[1].plot(self.history['val_iou'], label='Val', marker='s')\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('IoU')\n",
        "        axes[1].set_title('IoU')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(self.save_dir / 'training_progress.png', dpi=150)\n",
        "        plt.show()\n",
        "\n",
        "    def train(self, train_loader, val_loader, epochs):\n",
        "        print(f\"\\nüöÄ Starting training for {epochs} epochs.. .\\n\")\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Epoch {epoch}/{epochs}\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            train_loss, train_iou = self.train_epoch(train_loader)\n",
        "            val_loss, val_iou = self.validate(val_loader)\n",
        "\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['train_iou'].append(train_iou)\n",
        "            self.history['val_iou'].append(val_iou)\n",
        "\n",
        "            print(f\"\\nüìä Summary:\")\n",
        "            print(f\"   Train - Loss: {train_loss:.4f}, IoU: {train_iou:.4f}\")\n",
        "            print(f\"   Val   - Loss: {val_loss:. 4f}, IoU: {val_iou:.4f}\")\n",
        "\n",
        "            is_best = val_loss < self.best_val_loss\n",
        "            if is_best:\n",
        "                self. best_val_loss = val_loss\n",
        "\n",
        "            self.save_checkpoint(epoch, is_best)\n",
        "\n",
        "            if epoch % 5 == 0:\n",
        "                clear_output(wait=True)\n",
        "                self.plot_progress()\n",
        "\n",
        "        print(f\"\\n‚úÖ Training complete! Best val loss: {self.best_val_loss:.4f}\")\n",
        "        self.plot_progress()\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# STEP 9: Model Exporter\n",
        "# -----------------------------------------------------------------------------\n",
        "class ModelExporter:\n",
        "    def __init__(self, model_path):\n",
        "        self.model_path = Path(model_path)\n",
        "\n",
        "    def generate_version(self):\n",
        "        return f\"v_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "    def export_model(self, trainer, config):\n",
        "        version = self.generate_version()\n",
        "        export_dir = self.model_path / version\n",
        "        export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        print(f\"\\nüì¶ Exporting model:  {version}\")\n",
        "\n",
        "        # Save weights\n",
        "        torch.save(trainer. model.state_dict(), export_dir / \"weights.pth\")\n",
        "\n",
        "        # Create metadata\n",
        "        metadata = {\n",
        "            \"model_name\": config['model']['name'],\n",
        "            \"version\": version,\n",
        "            \"created_at\": datetime.now().isoformat(),\n",
        "            \"architecture\": {\n",
        "                \"type\": config['model']['architecture'],\n",
        "                \"input_shape\": [1, 512, 512],\n",
        "                \"unet_channels\": config['model']['unet_channels'],\n",
        "                \"out_channels\": 1\n",
        "            },\n",
        "            \"training\":  config['training'],\n",
        "            \"performance\": {\n",
        "                \"final_train_loss\": trainer.history['train_loss'][-1],\n",
        "                \"final_val_loss\": trainer.history['val_loss'][-1],\n",
        "                \"best_val_loss\": trainer.best_val_loss,\n",
        "                \"final_train_iou\": trainer.history['train_iou'][-1],\n",
        "                \"final_val_iou\": trainer.history['val_iou'][-1],\n",
        "                \"best_val_iou\": max(trainer.history['val_iou'])\n",
        "            },\n",
        "            \"data_info\": {\n",
        "                \"num_videos\": len(data_loader.video_files),\n",
        "                \"augmentation\":  config['augmentation']['enabled']\n",
        "            },\n",
        "            \"compatibility\": {\n",
        "                \"deeptrack_version\": dt_version,\n",
        "                \"torch_version\": torch.__version__,\n",
        "                \"python_version\": f\"{sys.version_info.major}.{sys.version_info. minor}\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open(export_dir / \"metadata.json\", 'w') as f:\n",
        "            json.dump(metadata, f, indent=2)\n",
        "\n",
        "        # Save config\n",
        "        with open(export_dir / \"config.json\", 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        # Copy plot\n",
        "        shutil.copy(trainer.save_dir / 'training_progress.png', export_dir / 'training_progress.png')\n",
        "\n",
        "        # Create model card\n",
        "        card = f\"\"\"# Model:  {config['model']['name']}\n",
        "\n",
        "**Version:** {version}\n",
        "**Created:** {metadata['created_at']}\n",
        "**Architecture:** {metadata['architecture']['type']. upper()}\n",
        "\n",
        "## Performance\n",
        "\n",
        "| Metric | Train | Validation | Best |\n",
        "|--------|-------|------------|------|\n",
        "| Loss | {metadata['performance']['final_train_loss']:.4f} | {metadata['performance']['final_val_loss']:.4f} | {metadata['performance']['best_val_loss']:.4f} |\n",
        "| IoU | {metadata['performance']['final_train_iou']:. 4f} | {metadata['performance']['final_val_iou']:.4f} | {metadata['performance']['best_val_iou']:.4f} |\n",
        "\n",
        "## Architecture\n",
        "\n",
        "- Type: {metadata['architecture']['type']. upper()}\n",
        "- Channels: {metadata['architecture']['unet_channels']}\n",
        "- Input:  {metadata['architecture']['input_shape']}\n",
        "\n",
        "## Training\n",
        "\n",
        "- Epochs: {config['training']['epochs']}\n",
        "- Batch Size: {config['training']['batch_size']}\n",
        "- Learning Rate:  {config['training']['learning_rate']}\n",
        "\n",
        "## Usage\n",
        "\n",
        "Download this model to your local DeepTrack MPT Studio app!\n",
        "\n",
        "```python\n",
        "from src.engines.ai_engine import DeepTrackEngine\n",
        "engine = DeepTrackEngine()\n",
        "engine.load_model(\"weights.pth\", \"metadata.json\")\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "        with open(export_dir / \"MODEL_CARD.md\", 'w') as f:\n",
        "            f.write(card)\n",
        "\n",
        "        print(f\"‚úÖ Model exported to {export_dir}\")\n",
        "        return export_dir\n",
        "\n",
        "\n",
        "# At the very end of CELL 1:\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ ALL COMPONENTS LOADED SUCCESSFULLY!\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nüìã NEXT STEPS:\")\n",
        "print(\"   1. Ensure videos are uploaded to Google Drive\")\n",
        "print(\"   2. Configure training parameters above\")\n",
        "print(\"   3. Run the training cell below\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "id": "5ZGeRCyNpUnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ‚ÄÅ EXECUTE TRAINING PIPELINE\n",
        "# ============================================================================\n",
        "# Run this cell to start training!\n",
        "# ============================================================================\n",
        "\n",
        "# Get configuration from widgets\n",
        "config = config_manager.get_config()\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üöÄ STARTING TRAINING PIPELINE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
        "print(f\"   Model: {config['model']['name']}\")\n",
        "print(f\"   Architecture: {config['model']['architecture']. upper()}\")\n",
        "print(f\"   Epochs: {config['training']['epochs']}\")\n",
        "print(f\"   Batch Size: {config['training']['batch_size']}\")\n",
        "print(f\"   Learning Rate: {config['training']['learning_rate']}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Prepare datasets\n",
        "train_loader, val_loader = prepare_datasets(data_loader, config)\n",
        "\n",
        "# Create model\n",
        "model = create_model(config)\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(model, config, LOG_PATH / 'current_training')\n",
        "\n",
        "# Start training\n",
        "trainer.train(train_loader, val_loader, config['training']['epochs'])\n",
        "\n",
        "# Export model\n",
        "exporter = ModelExporter(MODEL_PATH)\n",
        "export_dir = exporter.export_model(trainer, config)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üéâ TRAINING COMPLETE!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nüì¶ Model saved to: {export_dir}\")\n",
        "print(f\"\\nüì• Download your trained model from Google Drive!\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "id": "82rVSLsPbkLz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}