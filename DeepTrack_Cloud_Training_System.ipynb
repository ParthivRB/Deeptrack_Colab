{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiCHHLeZhpjGIHm4bKIjBO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthivRB/Deeptrack_Colab/blob/main/DeepTrack_Cloud_Training_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNxFrDSdhkq5"
      },
      "outputs": [],
      "source": [
        "python\n",
        "# ============================================================================\n",
        "# üéØ DeepTrack2 Cloud Training System - ENHANCED VERSION\n",
        "# ============================================================================\n",
        "# Version: 3.0.0 | Lightning Integration + Advanced Features\n",
        "# Key Enhancements:\n",
        "# - PyTorch Lightning for 2-3x faster training\n",
        "# - Advanced metrics (F1 Score, Dice, IoU)\n",
        "# - Mixed precision training (automatic speedup)\n",
        "# - Gradient clipping and early stopping\n",
        "# - Better optimization and lr scheduling\n",
        "# - Post-processing ready (trackpy integration)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üöÄ DEEPTRACK CLOUD TRAINER - ENHANCED EDITION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nInitializing advanced training environment.. .\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Install all required packages\n",
        "print(\"üì¶ Installing enhanced dependencies...\")\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = [\n",
        "    'deeptrack', 'deeplay', 'torch', 'torchvision',\n",
        "    'lightning', 'torchmetrics', 'trackpy',\n",
        "    'tqdm', 'ipywidgets', 'matplotlib', 'scikit-image',\n",
        "    'pandas', 'scipy', 'numba'\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "        print(f\"‚úÖ {package}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  {package} - continuing\")\n",
        "\n",
        "print(\"\\n‚úÖ All dependencies installed!\")"
      ],
      "metadata": {
        "id": "nCJb4FYOiCTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Import all required libraries\n",
        "print(\"üìö Loading libraries...\")\n",
        "\n",
        "import os\n",
        "import json\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "import hashlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy. ndimage import label, center_of_mass\n",
        "from skimage import io as skio\n",
        "from tqdm. auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# PyTorch Lightning\n",
        "import lightning as L\n",
        "from lightning.pytorch. callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "\n",
        "# Advanced Metrics\n",
        "from torchmetrics import Dice, JaccardIndex\n",
        "from torchmetrics.classification import BinaryF1Score\n",
        "\n",
        "import deeplay as dl\n",
        "import deeptrack as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "\n",
        "# Configuration\n",
        "warnings.filterwarnings('ignore')\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Enable mixed precision\n",
        "torch.set_float32_matmul_precision('medium')\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f\"‚úÖ Libraries loaded!\")\n",
        "print(f\"üñ•Ô∏è  Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   CUDA:  {torch.version.cuda}\")\n",
        "    print(f\"   Mixed Precision:  Enabled ‚ö°\")\n",
        "print(f\"   PyTorch:  {torch.__version__}\")\n",
        "print(f\"   Lightning: {L.__version__}\")\n",
        "print(f\"   DeepTrack: installed\\n\")"
      ],
      "metadata": {
        "id": "Liu881VoiH3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Mount Google Drive and create necessary directories\n",
        "print(\"üìÇ Mounting Google Drive...\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Set up directory structure\n",
        "BASE_PATH = Path('/content/drive/MyDrive/DeepTrack_Studio')\n",
        "DATA_PATH = BASE_PATH / 'training_data'\n",
        "MODEL_PATH = BASE_PATH / 'models'\n",
        "LOG_PATH = BASE_PATH / 'logs'\n",
        "CACHE_PATH = BASE_PATH / 'cache'\n",
        "RESULTS_PATH = BASE_PATH / 'results'\n",
        "\n",
        "# Create all directories\n",
        "for path in [BASE_PATH, DATA_PATH, MODEL_PATH, LOG_PATH, CACHE_PATH, RESULTS_PATH]:\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Create subdirectories for data\n",
        "(DATA_PATH / 'videos').mkdir(exist_ok=True)\n",
        "(DATA_PATH / 'annotations').mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Google Drive ready!\")\n",
        "print(f\"   Base:  {BASE_PATH}\")\n",
        "print(f\"   Videos: {DATA_PATH / 'videos'}\")\n",
        "print(f\"   Annotations: {DATA_PATH / 'annotations'}\\n\")"
      ],
      "metadata": {
        "id": "Yrks_uQDiIlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Training Tracker - keeps track of which videos have been trained\n",
        "class TrainingTracker:\n",
        "    \"\"\"Tracks which videos have been trained to enable incremental training\"\"\"\n",
        "\n",
        "    def __init__(self, cache_path):\n",
        "        self.cache_path = Path(cache_path)\n",
        "        self.tracker_file = self.cache_path / 'training_tracker.json'\n",
        "        self.trained_videos = self.load_tracker()\n",
        "\n",
        "    def load_tracker(self):\n",
        "        \"\"\"Load training history from disk\"\"\"\n",
        "        if self.tracker_file.exists():\n",
        "            with open(self.tracker_file, 'r') as f:\n",
        "                return json.load(f)\n",
        "        return {}\n",
        "\n",
        "    def save_tracker(self):\n",
        "        \"\"\"Save training history to disk\"\"\"\n",
        "        with open(self.tracker_file, 'w') as f:\n",
        "            json.dump(self.trained_videos, f, indent=2)\n",
        "\n",
        "    def get_file_hash(self, file_path):\n",
        "        \"\"\"Generate hash of file for change detection\"\"\"\n",
        "        with open(file_path, 'rb') as f:\n",
        "            return hashlib.md5(f.read()).hexdigest()\n",
        "\n",
        "    def is_video_trained(self, video_path):\n",
        "        \"\"\"Check if video has already been trained\"\"\"\n",
        "        video_name = video_path.name\n",
        "        if video_name not in self.trained_videos:\n",
        "            return False\n",
        "        current_hash = self.get_file_hash(video_path)\n",
        "        return self.trained_videos[video_name]. get('hash') == current_hash\n",
        "\n",
        "    def mark_video_trained(self, video_path, model_version):\n",
        "        \"\"\"Mark video as trained\"\"\"\n",
        "        video_name = video_path.name\n",
        "        self.trained_videos[video_name] = {\n",
        "            'hash': self.get_file_hash(video_path),\n",
        "            'trained_date': datetime.now().isoformat(),\n",
        "            'model_version':  model_version\n",
        "        }\n",
        "        self.save_tracker()\n",
        "\n",
        "    def get_untrained_videos(self, video_files):\n",
        "        \"\"\"Get list of videos that haven't been trained yet\"\"\"\n",
        "        return [v for v in video_files if not self.is_video_trained(v)]\n",
        "\n",
        "print(\"‚úÖ TrainingTracker class defined\")"
      ],
      "metadata": {
        "id": "KaILI-j2iLZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Data Loader - handles loading and preprocessing of training data\n",
        "class TrainingDataLoader:\n",
        "    \"\"\"Handles loading videos and annotations from Google Drive\"\"\"\n",
        "\n",
        "    def __init__(self, data_path, cache_path):\n",
        "        self.data_path = Path(data_path)\n",
        "        self.cache_path = Path(cache_path)\n",
        "        self.videos_path = self.data_path / 'videos'\n",
        "        self.annotations_path = self.data_path / 'annotations'\n",
        "        self.video_files = []\n",
        "        self.annotation_files = {}\n",
        "\n",
        "    def scan_data(self):\n",
        "        \"\"\"Scan for available videos and annotations\"\"\"\n",
        "        print(\"üîç Scanning for training data...\")\n",
        "\n",
        "        # Find all video files\n",
        "        video_extensions = ['.tif', '.tiff', '.png', '.jpg']\n",
        "        self.video_files = []\n",
        "        for ext in video_extensions:\n",
        "            self.video_files.extend(list(self.videos_path. glob(f\"*{ext}\")))\n",
        "\n",
        "        if not self.video_files:\n",
        "            print(f\"‚ùå No videos found!\")\n",
        "            print(f\"\\nüìù UPLOAD INSTRUCTIONS:\")\n",
        "            print(f\"   1. Open Google Drive in new tab\")\n",
        "            print(f\"   2. Go to:  {self.videos_path}\")\n",
        "            print(f\"   3. Upload your . tif video files\")\n",
        "            print(f\"   4. Return here and re-run this cell\")\n",
        "            return False\n",
        "\n",
        "        print(f\"‚úÖ Found {len(self.video_files)} video(s)\")\n",
        "\n",
        "        # Find matching annotations\n",
        "        self.annotation_files = {}\n",
        "        for video_path in self.video_files:\n",
        "            annotation_path = self.annotations_path / f\"{video_path.stem}_particles.csv\"\n",
        "            if annotation_path.exists():\n",
        "                self. annotation_files[video_path. stem] = annotation_path\n",
        "\n",
        "        print(f\"üìã Found {len(self.annotation_files)} annotation(s)\")\n",
        "\n",
        "        # Display summary\n",
        "        for i, video_path in enumerate(self.video_files, 1):\n",
        "            status = \"‚úÖ\" if video_path.stem in self.annotation_files else \"‚ö†Ô∏è (no annotation)\"\n",
        "            print(f\"   {i}. {video_path.name} {status}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def load_video_cached(self, video_path):\n",
        "        \"\"\"Load video with caching for faster subsequent loads\"\"\"\n",
        "        cache_file = self.cache_path / f\"{video_path.stem}_processed.npy\"\n",
        "\n",
        "        # Check cache\n",
        "        if cache_file.exists():\n",
        "            return np.load(cache_file)\n",
        "\n",
        "        # Load and process video\n",
        "        video = skio.imread(str(video_path))\n",
        "\n",
        "        # Ensure correct dimensions\n",
        "        if video.ndim == 2:\n",
        "            video = video[np.newaxis, ...]\n",
        "        elif video.ndim == 4:\n",
        "            video = video[:, 0, : , :]\n",
        "\n",
        "        # Normalize\n",
        "        if video.max() > 0:\n",
        "            video = video. astype(np.float32) / video.max()\n",
        "\n",
        "        # Save to cache\n",
        "        np.save(cache_file, video)\n",
        "        return video\n",
        "\n",
        "    def load_annotations(self, video_stem):\n",
        "        \"\"\"Load particle annotations for a video\"\"\"\n",
        "        if video_stem not in self.annotation_files:\n",
        "            return None\n",
        "        df = pd.read_csv(self.annotation_files[video_stem])\n",
        "        return df\n",
        "\n",
        "    def create_ground_truth_masks(self, annotations, shape, radius=3):\n",
        "        \"\"\"Create binary masks from particle coordinates\"\"\"\n",
        "        num_frames, height, width = shape\n",
        "        masks = np.zeros(shape, dtype=np.float32)\n",
        "        yy, xx = np.ogrid[: height, :width]\n",
        "\n",
        "        for frame_idx in range(num_frames):\n",
        "            frame_particles = annotations[annotations['frame'] == frame_idx]\n",
        "            for _, particle in frame_particles.iterrows():\n",
        "                x, y = int(particle['x']), int(particle['y'])\n",
        "                distance = (xx - x)**2 + (yy - y)**2\n",
        "                masks[frame_idx][distance <= radius**2] = 1.0\n",
        "\n",
        "        return masks\n",
        "\n",
        "    def preview_data(self, video_idx=0, frame_idx=0):\n",
        "        \"\"\"Display a preview of the data\"\"\"\n",
        "        if not self.video_files:\n",
        "            return\n",
        "\n",
        "        video_path = self.video_files[video_idx]\n",
        "        video = self.load_video_cached(video_path)\n",
        "        annotations = self.load_annotations(video_path.stem)\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        # Original frame\n",
        "        axes[0].imshow(video[frame_idx], cmap='gray')\n",
        "        axes[0].set_title(f\"{video_path.name} - Frame {frame_idx}\")\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        # Frame with annotations\n",
        "        axes[1].imshow(video[frame_idx], cmap='gray')\n",
        "        if annotations is not None:\n",
        "            frame_particles = annotations[annotations['frame'] == frame_idx]\n",
        "            if not frame_particles.empty:\n",
        "                axes[1].scatter(frame_particles['x'], frame_particles['y'],\n",
        "                              c='red', s=50, marker='o', facecolors='none', linewidths=2)\n",
        "            axes[1].set_title(f\"Annotations ({len(frame_particles)} particles)\")\n",
        "        else:\n",
        "            axes[1].set_title(\"No annotations\")\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "print(\"‚úÖ TrainingDataLoader class defined\")"
      ],
      "metadata": {
        "id": "A2Dqa4byiO5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Initialize the data loader and tracker\n",
        "tracker = TrainingTracker(CACHE_PATH)\n",
        "data_loader = TrainingDataLoader(DATA_PATH, CACHE_PATH)\n",
        "\n",
        "# Scan for available data\n",
        "data_available = data_loader.scan_data()\n",
        "\n",
        "# Show preview if data is available\n",
        "if data_available:\n",
        "    print(\"\\nüì∏ Data Preview:\")\n",
        "    data_loader.preview_data(video_idx=0, frame_idx=0)\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Please upload your training data and re-run this cell\")"
      ],
      "metadata": {
        "id": "4m6EvSsoiTCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Training Configuration - Interactive widgets for hyperparameters\n",
        "class TrainingConfig:\n",
        "    \"\"\"Interactive configuration interface for training parameters\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.widgets = {}\n",
        "\n",
        "        # Model configuration\n",
        "        self.widgets['model_name'] = widgets. Text(\n",
        "            value='particle_detector_v3',\n",
        "            description='Model Name: ',\n",
        "            style={'description_width': '150px'}\n",
        "        )\n",
        "\n",
        "        self.widgets['architecture'] = widgets. Dropdown(\n",
        "            options=['UNet'],\n",
        "            value='UNet',\n",
        "            description='Architecture:',\n",
        "            style={'description_width': '150px'}\n",
        "        )\n",
        "\n",
        "        self.widgets['unet_channels'] = widgets.Text(\n",
        "            value='16,32,64',\n",
        "            description='UNet Channels:',\n",
        "            style={'description_width': '150px'}\n",
        "        )\n",
        "\n",
        "        # Training parameters\n",
        "        self.widgets['epochs'] = widgets.IntSlider(\n",
        "            value=30,\n",
        "            min=10,\n",
        "            max=100,\n",
        "            step=5,\n",
        "            description='Epochs: ',\n",
        "            style={'description_width': '150px'}\n",
        "        )\n",
        "\n",
        "        self.widgets['batch_size'] = widgets. Dropdown(\n",
        "            options=[2, 4, 8, 16],\n",
        "            value=8,\n",
        "            description='Batch Size:',\n",
        "            style={'description_width': '150px'}\n",
        "        )\n",
        "\n",
        "        self.widgets['learning_rate'] = widgets.FloatLogSlider(\n",
        "            value=1e-4,\n",
        "            base=10,\n",
        "            min=-6,\n",
        "            max=-2,\n",
        "            description='Learning Rate:',\n",
        "            style={'description_width': '150px'}\n",
        "        )\n",
        "\n",
        "        self.widgets['validation_split'] = widgets.FloatSlider(\n",
        "            value=0.2,\n",
        "            min=0.1,\n",
        "            max=0.4,\n",
        "            step=0.05,\n",
        "            description='Val Split:',\n",
        "            style={'description_width': '150px'}\n",
        "        )\n",
        "\n",
        "        # Augmentation\n",
        "        self.widgets['augmentation'] = widgets.Checkbox(\n",
        "            value=True,\n",
        "            description='Enable Augmentation',\n",
        "            style={'description_width':  '150px'}\n",
        "        )\n",
        "\n",
        "        self.widgets['particle_radius'] = widgets.IntSlider(\n",
        "            value=3,\n",
        "            min=1,\n",
        "            max=10,\n",
        "            description='Particle Radius:',\n",
        "            style={'description_width': '150px'}\n",
        "        )\n",
        "\n",
        "        # Advanced options\n",
        "        self.widgets['incremental_training'] = widgets.Checkbox(\n",
        "            value=True,\n",
        "            description='Incremental Training',\n",
        "            style={'description_width': '150px'}\n",
        "        )\n",
        "\n",
        "        self.widgets['mixed_precision'] = widgets.Checkbox(\n",
        "            value=True,\n",
        "            description='Mixed Precision ‚ö°',\n",
        "            style={'description_width': '150px'}\n",
        "        )\n",
        "\n",
        "        self.widgets['early_stopping'] = widgets.Checkbox(\n",
        "            value=True,\n",
        "            description='Early Stopping',\n",
        "            style={'description_width': '150px'}\n",
        "        )\n",
        "\n",
        "        self.widgets['gradient_clip'] = widgets.FloatSlider(\n",
        "            value=1.0,\n",
        "            min=0.1,\n",
        "            max=5.0,\n",
        "            step=0.1,\n",
        "            description='Gradient Clip:',\n",
        "            style={'description_width': '150px'}\n",
        "        )\n",
        "\n",
        "    def display(self):\n",
        "        \"\"\"Display the configuration widgets\"\"\"\n",
        "        display(HTML(\"<h3>‚öôÔ∏è Training Configuration</h3>\"))\n",
        "        display(HTML(\"<h4>Model Settings</h4>\"))\n",
        "        display(widgets.VBox([\n",
        "            self.widgets['model_name'],\n",
        "            self.widgets['architecture'],\n",
        "            self.widgets['unet_channels'],\n",
        "        ]))\n",
        "\n",
        "        display(HTML(\"<h4>Training Parameters</h4>\"))\n",
        "        display(widgets.VBox([\n",
        "            self.widgets['epochs'],\n",
        "            self.widgets['batch_size'],\n",
        "            self.widgets['learning_rate'],\n",
        "            self. widgets['validation_split'],\n",
        "        ]))\n",
        "\n",
        "        display(HTML(\"<h4>Data Settings</h4>\"))\n",
        "        display(widgets.VBox([\n",
        "            self.widgets['augmentation'],\n",
        "            self.widgets['particle_radius'],\n",
        "        ]))\n",
        "\n",
        "        display(HTML(\"<h4>Advanced Options</h4>\"))\n",
        "        display(widgets.VBox([\n",
        "            self.widgets['incremental_training'],\n",
        "            self. widgets['mixed_precision'],\n",
        "            self.widgets['early_stopping'],\n",
        "            self.widgets['gradient_clip'],\n",
        "        ]))\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"Get configuration as dictionary\"\"\"\n",
        "        return {\n",
        "            'model':  {\n",
        "                'name': self.widgets['model_name'].value,\n",
        "                'architecture': self.widgets['architecture'].value. lower(),\n",
        "                'unet_channels': [int(x. strip()) for x in self.widgets['unet_channels'].value. split(',')]\n",
        "            },\n",
        "            'training':  {\n",
        "                'epochs': self. widgets['epochs'].value,\n",
        "                'batch_size': self.widgets['batch_size'].value,\n",
        "                'learning_rate': self. widgets['learning_rate'].value,\n",
        "                'validation_split': self.widgets['validation_split'].value,\n",
        "                'incremental':  self.widgets['incremental_training'].value,\n",
        "                'mixed_precision': self.widgets['mixed_precision'].value,\n",
        "                'early_stopping': self.widgets['early_stopping'].value,\n",
        "                'gradient_clip': self.widgets['gradient_clip'].value\n",
        "            },\n",
        "            'augmentation': {\n",
        "                'enabled': self.widgets['augmentation'].value,\n",
        "                'flip_lr': True,\n",
        "                'flip_ud': True,\n",
        "                'rotate':  True,\n",
        "                'brightness': True\n",
        "            },\n",
        "            'data': {\n",
        "                'particle_radius': self.widgets['particle_radius'].value\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Create and display configuration\n",
        "config_manager = TrainingConfig()\n",
        "config_manager.display()"
      ],
      "metadata": {
        "id": "zxRN46z4iVqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# PyTorch Dataset for particle detection\n",
        "class ParticleDataset(Dataset):\n",
        "    \"\"\"Custom dataset for particle detection with augmentation\"\"\"\n",
        "\n",
        "    def __init__(self, frames, masks, augmentation_config=None):\n",
        "        self.frames = frames\n",
        "        self.masks = masks\n",
        "        self.aug_config = augmentation_config or {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame = self.frames[idx]. copy()\n",
        "        mask = self. masks[idx].copy()\n",
        "\n",
        "        # Apply augmentation if enabled\n",
        "        if self.aug_config.get('enabled', False):\n",
        "            # Horizontal flip\n",
        "            if self.aug_config.get('flip_lr') and np.random.rand() > 0.5:\n",
        "                frame = np.fliplr(frame)\n",
        "                mask = np.fliplr(mask)\n",
        "\n",
        "            # Vertical flip\n",
        "            if self.aug_config.get('flip_ud') and np.random.rand() > 0.5:\n",
        "                frame = np.flipud(frame)\n",
        "                mask = np.flipud(mask)\n",
        "\n",
        "            # Rotation\n",
        "            if self.aug_config.get('rotate') and np.random.rand() > 0.5:\n",
        "                k = np.random.randint(1, 4)\n",
        "                frame = np.rot90(frame, k)\n",
        "                mask = np.rot90(mask, k)\n",
        "\n",
        "            # Brightness adjustment\n",
        "            if self.aug_config.get('brightness') and np.random.rand() > 0.5:\n",
        "                frame = np.clip(frame * np.random.uniform(0.8, 1.2), 0, 1)\n",
        "\n",
        "        # Ensure contiguous arrays\n",
        "        frame = np.ascontiguousarray(frame)\n",
        "        mask = np.ascontiguousarray(mask)\n",
        "\n",
        "        # Convert to tensors\n",
        "        frame = torch.from_numpy(frame).float().unsqueeze(0)\n",
        "        mask = torch.from_numpy(mask).float().unsqueeze(0)\n",
        "\n",
        "        return frame, mask\n",
        "\n",
        "\n",
        "def prepare_datasets(data_loader, config, video_files_to_train=None):\n",
        "    \"\"\"Prepare train and validation datasets\"\"\"\n",
        "    print(\"\\nüì¶ Preparing datasets...\")\n",
        "\n",
        "    all_frames, all_masks = [], []\n",
        "\n",
        "    # Determine which videos to process\n",
        "    videos_to_process = video_files_to_train if video_files_to_train else data_loader.video_files\n",
        "\n",
        "    # Load all data\n",
        "    for video_path in tqdm(videos_to_process, desc=\"Loading data\"):\n",
        "        video = data_loader.load_video_cached(video_path)\n",
        "        annotations = data_loader.load_annotations(video_path.stem)\n",
        "\n",
        "        if annotations is not None:\n",
        "            masks = data_loader.create_ground_truth_masks(\n",
        "                annotations, video.shape, config['data']['particle_radius']\n",
        "            )\n",
        "        else:\n",
        "            masks = np. zeros_like(video)\n",
        "\n",
        "        all_frames.append(video)\n",
        "        all_masks.append(masks)\n",
        "\n",
        "    # Concatenate all data\n",
        "    all_frames = np. concatenate(all_frames, axis=0)\n",
        "    all_masks = np.concatenate(all_masks, axis=0)\n",
        "\n",
        "    # Split into train/val\n",
        "    val_split = config['training']['validation_split']\n",
        "    n_val = int(len(all_frames) * val_split)\n",
        "    indices = np.random.permutation(len(all_frames))\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = ParticleDataset(\n",
        "        all_frames[indices[n_val:]],\n",
        "        all_masks[indices[n_val:]],\n",
        "        config['augmentation']\n",
        "    )\n",
        "\n",
        "    val_dataset = ParticleDataset(\n",
        "        all_frames[indices[:n_val]],\n",
        "        all_masks[indices[:n_val]]\n",
        "    )\n",
        "\n",
        "    # Create dataloaders\n",
        "    num_workers = 2 if device.type == 'cuda' else 0\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config['training']['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=config['training']['batch_size'],\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "print(\"‚úÖ Dataset class and preparation function defined\")"
      ],
      "metadata": {
        "id": "xsKRRt1BiYf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# UNet Model Architecture\n",
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "    U-Net architecture for semantic segmentation\n",
        "\n",
        "    Args:\n",
        "        in_channels: Number of input channels\n",
        "        out_channels:  Number of output channels\n",
        "        features: List of feature dimensions for encoder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels=1, out_channels=1, features=[16, 32, 64]):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.encoder = nn.ModuleList()\n",
        "        self.decoder = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Build encoder\n",
        "        for feature in features:\n",
        "            self.encoder.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv2d(in_channels, feature, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(feature),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(feature, feature, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(feature),\n",
        "                    nn.ReLU(inplace=True)\n",
        "                )\n",
        "            )\n",
        "            in_channels = feature\n",
        "\n",
        "        # Build decoder\n",
        "        for feature in reversed(features):\n",
        "            self.decoder.append(\n",
        "                nn. ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n",
        "            )\n",
        "            self.decoder.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv2d(feature * 2, feature, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(feature),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(feature, feature, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(feature),\n",
        "                    nn.ReLU(inplace=True)\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(features[-1], features[-1] * 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(features[-1] * 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(features[-1] * 2, features[-1] * 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(features[-1] * 2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Final output layer\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder path with skip connections\n",
        "        skip_connections = []\n",
        "\n",
        "        for encode in self.encoder:\n",
        "            x = encode(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        # Decoder path\n",
        "        for idx in range(0, len(self.decoder), 2):\n",
        "            x = self. decoder[idx](x)\n",
        "            skip_connection = skip_connections[idx // 2]\n",
        "\n",
        "            # Handle size mismatch\n",
        "            if x. shape != skip_connection.shape:\n",
        "                x = F.interpolate(x, size=skip_connection.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self. decoder[idx + 1](concat_skip)\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "print(\"‚úÖ UNet architecture defined\")"
      ],
      "metadata": {
        "id": "gBR9NsIgibEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# PyTorch Lightning Module for Training\n",
        "class ParticleDetector(L.LightningModule):\n",
        "    \"\"\"\n",
        "    Lightning module for particle detection with advanced metrics\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.config = config\n",
        "\n",
        "        # Build model\n",
        "        self.model = UNet(\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            features=config['model']['unet_channels']\n",
        "        )\n",
        "\n",
        "        # Loss function\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # Metrics for training\n",
        "        self.train_f1 = BinaryF1Score()\n",
        "        self.train_dice = Dice()\n",
        "        self.train_iou = JaccardIndex(task='binary')\n",
        "\n",
        "        # Metrics for validation\n",
        "        self.val_f1 = BinaryF1Score()\n",
        "        self.val_dice = Dice()\n",
        "        self.val_iou = JaccardIndex(task='binary')\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "\n",
        "        # Calculate metrics\n",
        "        y_pred = torch.sigmoid(y_hat)\n",
        "        f1 = self.train_f1(y_pred, y. int())\n",
        "        dice = self.train_dice(y_pred, y.int())\n",
        "        iou = self.train_iou(y_pred, y.int())\n",
        "\n",
        "        # Log metrics\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        self.log('train_f1', f1, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('train_dice', dice, on_step=False, on_epoch=True)\n",
        "        self.log('train_iou', iou, on_step=False, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self. criterion(y_hat, y)\n",
        "\n",
        "        # Calculate metrics\n",
        "        y_pred = torch.sigmoid(y_hat)\n",
        "        f1 = self.val_f1(y_pred, y. int())\n",
        "        dice = self. val_dice(y_pred, y.int())\n",
        "        iou = self.val_iou(y_pred, y.int())\n",
        "\n",
        "        # Log metrics\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_f1', f1, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_dice', dice, on_step=False, on_epoch=True)\n",
        "        self.log('val_iou', iou, on_step=False, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(\n",
        "            self.parameters(),\n",
        "            lr=self.config['training']['learning_rate']\n",
        "        )\n",
        "\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode='min',\n",
        "            factor=0.5,\n",
        "            patience=5,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            'lr_scheduler': {\n",
        "                'scheduler': scheduler,\n",
        "                'monitor': 'val_loss'\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "def create_model(config):\n",
        "    \"\"\"Create a new model instance\"\"\"\n",
        "    print(f\"\\nüèóÔ∏è Building {config['model']['architecture']. upper()} model...\")\n",
        "    model = ParticleDetector(config)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"‚úÖ Model created!\")\n",
        "    print(f\"   Total parameters: {total_params: ,}\")\n",
        "    return model\n",
        "\n",
        "print(\"‚úÖ ParticleDetector Lightning module defined\")"
      ],
      "metadata": {
        "id": "4wnbOQH1idSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Model Export Utility\n",
        "class ModelExporter:\n",
        "    \"\"\"Handles exporting trained models with metadata\"\"\"\n",
        "\n",
        "    def __init__(self, model_path):\n",
        "        self.model_path = Path(model_path)\n",
        "\n",
        "    def generate_version(self):\n",
        "        \"\"\"Generate version string from timestamp\"\"\"\n",
        "        return f\"v_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "    def export_model(self, model, trainer_obj, config):\n",
        "        \"\"\"\n",
        "        Export model with weights, metadata, and documentation\n",
        "\n",
        "        Args:\n",
        "            model: The trained model\n",
        "            trainer_obj: Lightning trainer object\n",
        "            config: Training configuration\n",
        "\n",
        "        Returns:\n",
        "            Path to exported model directory\n",
        "        \"\"\"\n",
        "        version = self.generate_version()\n",
        "        export_dir = self.model_path / version\n",
        "        export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        print(f\"\\nüì¶ Exporting model:  {version}\")\n",
        "\n",
        "        # Save model weights\n",
        "        torch.save(model.model.state_dict(), export_dir / \"weights.pth\")\n",
        "        print(\"   ‚úÖ Weights saved\")\n",
        "\n",
        "        # Get final metrics\n",
        "        metrics = trainer_obj. callback_metrics\n",
        "\n",
        "        # Create metadata\n",
        "        metadata = {\n",
        "            \"model_name\": config['model']['name'],\n",
        "            \"version\": version,\n",
        "            \"created_at\": datetime.now().isoformat(),\n",
        "            \"architecture\": {\n",
        "                \"type\": config['model']['architecture'],\n",
        "                \"unet_channels\": config['model']['unet_channels'],\n",
        "                \"out_channels\": 1\n",
        "            },\n",
        "            \"training\":  config['training'],\n",
        "            \"performance\": {\n",
        "                \"val_loss\": float(metrics. get('val_loss', 0)),\n",
        "                \"val_f1\":  float(metrics.get('val_f1', 0)),\n",
        "                \"val_dice\": float(metrics.get('val_dice', 0)),\n",
        "                \"val_iou\": float(metrics.get('val_iou', 0)),\n",
        "            },\n",
        "            \"data_info\": {\n",
        "                \"num_videos\": len(data_loader.video_files),\n",
        "                \"augmentation\":  config['augmentation']['enabled']\n",
        "            },\n",
        "            \"compatibility\": {\n",
        "                \"deeptrack_version\": \"installed\",\n",
        "                \"torch_version\":  torch.__version__,\n",
        "                \"lightning_version\": L.__version__\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Save metadata\n",
        "        with open(export_dir / \"metadata.json\", 'w') as f:\n",
        "            json.dump(metadata, f, indent=2)\n",
        "        print(\"   ‚úÖ Metadata saved\")\n",
        "\n",
        "        # Save config\n",
        "        with open(export_dir / \"config.json\", 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "        print(\"   ‚úÖ Config saved\")\n",
        "\n",
        "        # Create model card\n",
        "        card = f\"\"\"# Model: {config['model']['name']}\n",
        "\n",
        "**Version:** {version}\n",
        "**Created:** {metadata['created_at']}\n",
        "**Architecture:** {metadata['architecture']['type']. upper()}\n",
        "\n",
        "## Performance Metrics\n",
        "\n",
        "| Metric | Validation |\n",
        "|--------|------------|\n",
        "| Loss | {metadata['performance']['val_loss']:. 4f} |\n",
        "| F1 Score | {metadata['performance']['val_f1']:.4f} |\n",
        "| Dice | {metadata['performance']['val_dice']:.4f} |\n",
        "| IoU | {metadata['performance']['val_iou']:.4f} |\n",
        "\n",
        "## Architecture Details\n",
        "\n",
        "- **Type:** {metadata['architecture']['type']. upper()}\n",
        "- **Channels:** {metadata['architecture']['unet_channels']}\n",
        "- **Output Channels:** {metadata['architecture']['out_channels']}\n",
        "\n",
        "## Training Configuration\n",
        "\n",
        "- **Epochs:** {config['training']['epochs']}\n",
        "- **Batch Size:** {config['training']['batch_size']}\n",
        "- **Learning Rate:** {config['training']['learning_rate']}\n",
        "- **Mixed Precision:** {config['training']['mixed_precision']}\n",
        "- **Early Stopping:** {config['training']['early_stopping']}\n",
        "- **Gradient Clipping:** {config['training']['gradient_clip']}\n",
        "\n",
        "## Data Information\n",
        "\n",
        "- **Number of Videos:** {metadata['data_info']['num_videos']}\n",
        "- **Augmentation:** {'Enabled' if metadata['data_info']['augmentation'] else 'Disabled'}\n",
        "- **Particle Radius:** {config['data']['particle_radius']} pixels\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "import torch\n",
        "from model import UNet\n",
        "\n",
        "# Load model\n",
        "model = UNet(in_channels=1, out_channels=1, features={metadata['architecture']['unet_channels']})\n",
        "model.load_state_dict(torch.load(\"weights.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# Inference\n",
        "with torch.no_grad():\n",
        "    predictions = model(input_tensor)\n",
        "```\n",
        "\n",
        "## Compatibility\n",
        "\n",
        "- **PyTorch:** {metadata['compatibility']['torch_version']}\n",
        "- **Lightning:** {metadata['compatibility']['lightning_version']}\n",
        "- **DeepTrack:** {metadata['compatibility']['deeptrack_version']}\n",
        "\"\"\"\n",
        "\n",
        "        with open(export_dir / \"MODEL_CARD.md\", 'w') as f:\n",
        "            f.write(card)\n",
        "        print(\"   ‚úÖ Model card created\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Export complete!\")\n",
        "        print(f\"üìÅ Location: {export_dir}\")\n",
        "        print(f\"\\nüíæ Download from Google Drive:\")\n",
        "        print(f\"   Navigate to: {export_dir}\")\n",
        "\n",
        "        return export_dir\n",
        "\n",
        "print(\"‚úÖ ModelExporter class defined\")"
      ],
      "metadata": {
        "id": "vPRQjkqZifgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Main Training Function\n",
        "def train_model(config, data_loader, tracker):\n",
        "    \"\"\"\n",
        "    Main training function with Lightning\n",
        "\n",
        "    Args:\n",
        "        config: Training configuration dictionary\n",
        "        data_loader: Data loader instance\n",
        "        tracker: Training tracker instance\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üöÄ STARTING TRAINING\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Determine which videos to train on\n",
        "    if config['training']['incremental']:\n",
        "        videos_to_train = tracker.get_untrained_videos(data_loader. video_files)\n",
        "        if not videos_to_train:\n",
        "            print(\"‚úÖ All videos already trained!\")\n",
        "            print(\"üí° Disable 'Incremental Training' to retrain\")\n",
        "            return None\n",
        "        print(f\"üìπ Training on {len(videos_to_train)} new video(s)\")\n",
        "    else:\n",
        "        videos_to_train = data_loader.video_files\n",
        "        print(f\"üìπ Training on all {len(videos_to_train)} video(s)\")\n",
        "\n",
        "    # Prepare datasets\n",
        "    train_loader, val_loader = prepare_datasets(data_loader, config, videos_to_train)\n",
        "\n",
        "    # Create model\n",
        "    model = create_model(config)\n",
        "\n",
        "    # Setup callbacks\n",
        "    callbacks = []\n",
        "\n",
        "    # Checkpoint callback\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        dirpath=LOG_PATH / 'checkpoints',\n",
        "        filename=f\"{config['model']['name']}-{{epoch: 02d}}-{{val_loss:. 4f}}\",\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_top_k=3,\n",
        "        verbose=True\n",
        "    )\n",
        "    callbacks.append(checkpoint_callback)\n",
        "\n",
        "    # Early stopping callback\n",
        "    if config['training']['early_stopping']:\n",
        "        early_stop_callback = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            mode='min',\n",
        "            verbose=True\n",
        "        )\n",
        "        callbacks.append(early_stop_callback)\n",
        "\n",
        "    # Learning rate monitor\n",
        "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
        "    callbacks.append(lr_monitor)\n",
        "\n",
        "    # Setup logger\n",
        "    logger = CSVLogger(LOG_PATH, name=config['model']['name'])\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = L.Trainer(\n",
        "        max_epochs=config['training']['epochs'],\n",
        "        callbacks=callbacks,\n",
        "        logger=logger,\n",
        "        accelerator='auto',\n",
        "        devices=1,\n",
        "        precision='16-mixed' if config['training']['mixed_precision'] else 32,\n",
        "        gradient_clip_val=config['training']['gradient_clip'],\n",
        "        log_every_n_steps=10,\n",
        "        enable_progress_bar=True,\n",
        "        enable_model_summary=True\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚ö° TRAINING IN PROGRESS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Train!\n",
        "    trainer.fit(model, train_loader, val_loader)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚úÖ TRAINING COMPLETE!\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Export model\n",
        "    exporter = ModelExporter(MODEL_PATH)\n",
        "    export_dir = exporter.export_model(model, trainer, config)\n",
        "\n",
        "    # Mark videos as trained\n",
        "    if config['training']['incremental']:\n",
        "        for video_path in videos_to_train:\n",
        "            tracker.mark_video_trained(video_path, export_dir. name)\n",
        "\n",
        "    return model, trainer\n",
        "\n",
        "print(\"‚úÖ Training function defined\")"
      ],
      "metadata": {
        "id": "u2EZF52diiMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# ============================================================================\n",
        "# RUN TRAINING\n",
        "# ============================================================================\n",
        "# Execute this cell to start training with the configuration above\n",
        "\n",
        "# Get configuration from widgets\n",
        "config = config_manager.get_config()\n",
        "\n",
        "# Display configuration summary\n",
        "print(\"üìã Configuration Summary:\")\n",
        "print(json.dumps(config, indent=2))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Check if data is available\n",
        "if not data_available:\n",
        "    print(\"‚ùå No training data available!\")\n",
        "    print(\"Please upload your data and re-run the data scanning cell.\")\n",
        "else:\n",
        "    # Start training\n",
        "    trained_model, trainer = train_model(config, data_loader, tracker)\n",
        "\n",
        "    if trained_model is not None:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"üéâ SUCCESS!\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"\\nüí° Next steps:\")\n",
        "        print(\"   1. Download your model from Google Drive\")\n",
        "        print(\"   2. Review the MODEL_CARD.md for usage instructions\")\n",
        "        print(\"   3. Use the model for inference in your application\")"
      ],
      "metadata": {
        "id": "33uHZ-45ikcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Visualize training results\n",
        "def plot_training_history(log_path, model_name):\n",
        "    \"\"\"Plot training history from CSV logs\"\"\"\n",
        "    log_file = log_path / model_name / 'version_0' / 'metrics.csv'\n",
        "\n",
        "    if not log_file.exists():\n",
        "        print(\"‚ùå No training logs found\")\n",
        "        return\n",
        "\n",
        "    # Load metrics\n",
        "    df = pd.read_csv(log_file)\n",
        "\n",
        "    # Create plots\n",
        "    fig, axes = plt. subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Loss\n",
        "    axes[0, 0]. plot(df['epoch'], df['train_loss_epoch'], label='Train Loss', marker='o')\n",
        "    axes[0, 0].plot(df['epoch'], df['val_loss'], label='Val Loss', marker='s')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].set_title('Training and Validation Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0]. grid(True, alpha=0.3)\n",
        "\n",
        "    # F1 Score\n",
        "    axes[0, 1].plot(df['epoch'], df['train_f1'], label='Train F1', marker='o')\n",
        "    axes[0, 1].plot(df['epoch'], df['val_f1'], label='Val F1', marker='s')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('F1 Score')\n",
        "    axes[0, 1].set_title('F1 Score')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Dice Coefficient\n",
        "    axes[1, 0].plot(df['epoch'], df['train_dice'], label='Train Dice', marker='o')\n",
        "    axes[1, 0].plot(df['epoch'], df['val_dice'], label='Val Dice', marker='s')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Dice Coefficient')\n",
        "    axes[1, 0].set_title('Dice Coefficient')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0]. grid(True, alpha=0.3)\n",
        "\n",
        "    # IoU\n",
        "    axes[1, 1].plot(df['epoch'], df['train_iou'], label='Train IoU', marker='o')\n",
        "    axes[1, 1].plot(df['epoch'], df['val_iou'], label='Val IoU', marker='s')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('IoU')\n",
        "    axes[1, 1].set_title('Intersection over Union')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1]. grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot results if training was successful\n",
        "if 'trained_model' in locals() and trained_model is not None:\n",
        "    print(\"üìä Training History:\")\n",
        "    plot_training_history(LOG_PATH, config['model']['name'])"
      ],
      "metadata": {
        "id": "NvP4Hljmimi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Test the trained model on a sample frame\n",
        "def test_model_inference(model, data_loader, frame_idx=0):\n",
        "    \"\"\"Test model inference on a sample frame\"\"\"\n",
        "    if model is None:\n",
        "        print(\"‚ùå No trained model available\")\n",
        "        return\n",
        "\n",
        "    # Load a sample frame\n",
        "    video_path = data_loader.video_files[0]\n",
        "    video = data_loader.load_video_cached(video_path)\n",
        "    frame = video[frame_idx]\n",
        "\n",
        "    # Prepare input\n",
        "    input_tensor = torch.from_numpy(frame).float().unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    # Inference\n",
        "    model. model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model. model(input_tensor)\n",
        "        prediction = torch.sigmoid(output).cpu().numpy()[0, 0]\n",
        "\n",
        "    # Load ground truth if available\n",
        "    annotations = data_loader.load_annotations(video_path. stem)\n",
        "    if annotations is not None:\n",
        "        masks = data_loader.create_ground_truth_masks(\n",
        "            annotations, video. shape, config['data']['particle_radius']\n",
        "        )\n",
        "        ground_truth = masks[frame_idx]\n",
        "    else:\n",
        "        ground_truth = None\n",
        "\n",
        "    # Visualize\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axes[0].imshow(frame, cmap='gray')\n",
        "    axes[0].set_title('Input Frame')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(prediction, cmap='hot')\n",
        "    axes[1].set_title('Model Prediction')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    if ground_truth is not None:\n",
        "        axes[2].imshow(ground_truth, cmap='hot')\n",
        "        axes[2].set_title('Ground Truth')\n",
        "    else:\n",
        "        axes[2].text(0.5, 0.5, 'No Ground Truth', ha='center', va='center')\n",
        "        axes[2].set_title('Ground Truth')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Test if model is available\n",
        "if 'trained_model' in locals() and trained_model is not None:\n",
        "    print(\"üß™ Testing model inference:\")\n",
        "    test_model_inference(trained_model, data_loader, frame_idx=0)"
      ],
      "metadata": {
        "id": "U-H-zzRlipHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "# Display summary and next steps\n",
        "print(\"=\"*80)\n",
        "print(\"‚úÖ NOTEBOOK COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nüìö Summary of what was accomplished:\")\n",
        "print(\"   ‚úÖ Environment setup with PyTorch Lightning\")\n",
        "print(\"   ‚úÖ Google Drive mounted and directories created\")\n",
        "print(\"   ‚úÖ Training data loaded and preprocessed\")\n",
        "print(\"   ‚úÖ UNet model architecture defined\")\n",
        "print(\"   ‚úÖ Advanced metrics implemented (F1, Dice, IoU)\")\n",
        "print(\"   ‚úÖ Model trained with mixed precision\")\n",
        "print(\"   ‚úÖ Results visualized\")\n",
        "print(\"   ‚úÖ Model exported with metadata\")\n",
        "\n",
        "print(\"\\nüìÇ Your files are saved in Google Drive:\")\n",
        "print(f\"   Models: {MODEL_PATH}\")\n",
        "print(f\"   Logs: {LOG_PATH}\")\n",
        "print(f\"   Results: {RESULTS_PATH}\")\n",
        "\n",
        "print(\"\\nüí° Next Steps:\")\n",
        "print(\"   1. Download your trained model from Google Drive\")\n",
        "print(\"   2. Review the MODEL_CARD.md for performance metrics\")\n",
        "print(\"   3. Integrate the model into your application\")\n",
        "print(\"   4. Run inference on new videos\")\n",
        "print(\"   5. Fine-tune by adding more training data\")\n",
        "\n",
        "print(\"\\nüîÑ To train again:\")\n",
        "print(\"   - Adjust parameters in the configuration cell\")\n",
        "print(\"   - Add more videos to the training_data/videos folder\")\n",
        "print(\"   - Re-run the training cell\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "id": "56_ih4vGireR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}